{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "1_sequential.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/JHyunjun/SNU/blob/main/1_sequential.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j7jzlKKCp-XV"
      },
      "source": [
        "# Foundations: TensorFlow Tutorials\n",
        "\n",
        "This material is based on [TensrorFlow 2 quickstart for beginners](https://www.tensorflow.org/tutorials/quickstart/beginner) and may be copyrighted by the original writers. For educational uses only."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Skou3xLFp6vG"
      },
      "source": [
        "## Introduction\n",
        "\n",
        "This tutorial demonstrates the basic workflow of using TensorFlow. The goal of this tutorial is to build a simple linear model for classification. \n",
        "After loading the so-called MNIST data-set with images of hand-written digits, we define and optimize a simple mathematical model in TensorFlow. The results are then plotted and discussed.\n",
        "\n",
        "You should be familiar with basic linear algebra, Python and the Jupyter Notebook editor. It also helps if you have a basic understanding of Machine Learning and classification."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y1ikfkj8l9L9"
      },
      "source": [
        "This short introduction uses [Keras](https://www.tensorflow.org/guide/keras/overview) to:\n",
        "\n",
        "1. Build a neural network that classifies images.\n",
        "2. Train this neural network.\n",
        "3. And, finally, evaluate the accuracy of the model."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8ejfOWiDl99k"
      },
      "source": [
        "This is a [Google Colaboratory](https://colab.research.google.com/notebooks/welcome.ipynb) notebook file. Python programs are run directly in the browserâ€”a great way to learn and use TensorFlow. To follow this tutorial, run the notebook in Google Colab by clicking the button at the top of this page.\n",
        "\n",
        "1. In Colab, connect to a Python runtime: At the top-right of the menu bar, select *CONNECT*.\n",
        "2. Run all the notebook code cells: Select *Runtime* > *Run all*."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E4PQcKBp5-pZ"
      },
      "source": [
        "##Imports\n",
        "\n",
        "Download and install TensorFlow 2. Import TensorFlow into your program:\n",
        "\n",
        "Note: Upgrade `pip` to install the TensorFlow 2 package. See the [install guide](https://www.tensorflow.org/install) for details."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7JdowpjfnN7T"
      },
      "source": [
        "%matplotlib inline\n",
        "from __future__ import absolute_import, division, print_function\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jXk3lAeaU4mF"
      },
      "source": [
        "# Load the TensorBoard notebook extension\n",
        "%load_ext tensorboard\n",
        "# Clear any logs from previous runs\n",
        "!rm -rf ./logs/ \n",
        "%tensorboard --logdir logs/"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t9Poysvy6YQ6"
      },
      "source": [
        "## Load data\n",
        "\n",
        "The MNIST database of handwritten digits, has a training set of 60,000 examples, and a test set of 10,000 examples of 28x28 grayscale images. It is a good database for people who want to try learning techniques and pattern recognition methods.\n",
        "\n",
        "Load and prepare the [MNIST dataset](http://yann.lecun.com/exdb/mnist/). Convert the samples from integers to floating-point numbers:\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DLUM1IgtzGkE"
      },
      "source": [
        "mnist = tf.keras.datasets.mnist\n",
        "\n",
        "(x_train, y_train),(x_test, y_test) = mnist.load_data() # Load MNIST dataset using Keras\n",
        "x_train, x_test = x_train / 255.0, x_test / 255.0       # Convert the samples to floating-point numbers\n",
        "\n",
        "print('Train dataset size:', x_train.shape[0])\n",
        "print('Test dataset size:', x_test.shape[0])\n",
        "\n",
        "print('Image shape:', x_train.shape[1:3])\n",
        "print('num_classes:', np.unique(y_train))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7yLT9319643Q"
      },
      "source": [
        "# Plot train examples\n",
        "fig, axes = plt.subplots(1,10,figsize=(15,2), sharex=True, sharey=True)\n",
        "plt.suptitle('Train examples')\n",
        "for i in range(10):\n",
        "  axes[i].imshow(x_train[i], cmap=plt.cm.gray_r)\n",
        "  axes[i].set_title('label: {}'.format(y_train[i]))\n",
        "\n",
        "# Plot test examples\n",
        "fig, axes = plt.subplots(1,10,figsize=(15,2), sharex=True, sharey=True)\n",
        "plt.suptitle('Test examples')\n",
        "for i in range(10):\n",
        "  axes[i].imshow(x_test[i], cmap=plt.cm.gray_r)\n",
        "  axes[i].set_title('label: {}'.format(y_test[i]))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XYrO2NNnlaOi"
      },
      "source": [
        "## Define model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "80f7713c6b92"
      },
      "source": [
        "### When to use a Sequential model\n",
        "\n",
        "A `Sequential` model is appropriate for **a plain stack of layers**\n",
        "where each layer has **exactly one input tensor and one output tensor**.\n",
        "\n",
        "A Sequential model is **not appropriate** when:\n",
        "\n",
        "- Your model has multiple inputs or multiple outputs\n",
        "- Any of your layers has multiple inputs or multiple outputs\n",
        "- You need to do layer sharing\n",
        "- You want non-linear topology (e.g. a residual connection, a multi-branch\n",
        "model)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AUjU32vNmWHG"
      },
      "source": [
        "Build the `tf.keras.Sequential` model by stacking layers. Choose an optimizer and loss function for training:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gZQt9UGN6uTb"
      },
      "source": [
        "# Model definition\n",
        "model = tf.keras.models.Sequential([\n",
        "  tf.keras.layers.Flatten(input_shape=(28,28)),\n",
        "  tf.keras.layers.Dense(10)\n",
        "])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b4c7957e9913"
      },
      "source": [
        "You can also create a Sequential model incrementally via the `add()` method:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d54fde401054"
      },
      "source": [
        "model = tf.keras.models.Sequential()\n",
        "model.add(tf.keras.layers.Flatten(input_shape=(28,28)))\n",
        "model.add(tf.keras.layers.Dense(10))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qz_rp5zumk3x"
      },
      "source": [
        "For each example the model returns a vector of \"[logits](https://developers.google.com/machine-learning/glossary#logits)\" or \"[log-odds](https://developers.google.com/machine-learning/glossary#log-odds)\" scores, one for each class."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GYwy_-AbmkEs"
      },
      "source": [
        "predictions = model(x_train[:1]).numpy()\n",
        "predictions"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sUg3UrESmrZz"
      },
      "source": [
        "The `tf.nn.softmax` function converts these logits to \"probabilities\" for each class: "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0WD0V8SYmuhe"
      },
      "source": [
        "tf.nn.softmax(predictions).numpy()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LPET2ukcmtuC"
      },
      "source": [
        "Note: It is possible to bake this `tf.nn.softmax` in as the activation function for the last layer of the network. While this can make the model output more directly interpretable, this approach is discouraged as it's impossible to\n",
        "provide an exact and numerically stable loss calculation for all models when using a softmax output. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "36SMfXWSp5aw"
      },
      "source": [
        "##Define loss function"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mel0SCyjnB0U"
      },
      "source": [
        "The `losses.SparseCategoricalCrossentropy` loss takes a vector of logits and a `True` index and returns a scalar loss for each example."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dKdKRs9knEYh"
      },
      "source": [
        "# Define loss function\n",
        "loss_fn = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l8xPLY3znF_D"
      },
      "source": [
        "This loss is equal to the negative log probability of the true class:\n",
        "It is zero if the model is sure of the correct class.\n",
        "\n",
        "This untrained model gives probabilities close to random (1/10 for each class), so the initial loss should be close to `-tf.log(1/10) ~= 2.3`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NIP4Xl8enKnO"
      },
      "source": [
        "loss_fn(y_train[:1], predictions).numpy()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lrLwBQf4p8Wf"
      },
      "source": [
        "## Optimize model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yeTeuAKYmh-A"
      },
      "source": [
        "# Compile model graph\n",
        "model.compile(optimizer='adam', \n",
        "              loss=loss_fn,\n",
        "              metrics=['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G7Z1EtYWnSbX"
      },
      "source": [
        "The `Model.fit` method adjusts the model parameters to minimize the loss:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hlZT1UTMzbUw"
      },
      "source": [
        "# Optimize model\n",
        "model.fit(x_train, y_train, epochs=5,\n",
        "          callbacks=[tf.keras.callbacks.TensorBoard(\"./logs/keras\")])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_-b8e_XKnaIs"
      },
      "source": [
        "## Evaluate model\n",
        "The `Model.evaluate` method checks the models performance, usually on a \"[Validation-set](https://developers.google.com/machine-learning/glossary#validation-set)\" or \"[Test-set](https://developers.google.com/machine-learning/glossary#test-set)\"."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5fBpL9aGzkZ-"
      },
      "source": [
        "# Evaluate model performance\n",
        "model.evaluate(x_test, y_test, verbose=2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yeV52fQDndiL"
      },
      "source": [
        "The image classifier is now trained to ~92% accuracy on this dataset. To learn more, read the [TensorFlow tutorials](https://www.tensorflow.org/tutorials/)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R7RpGeWAnfo0"
      },
      "source": [
        "If you want your model to return a probability, you can wrap the trained model, and attach the softmax to it:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R6RuQ3-fohAi"
      },
      "source": [
        "probability_model = tf.keras.Sequential([\n",
        "  model,\n",
        "  tf.keras.layers.Softmax()\n",
        "])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M8CbaIeooh1Z"
      },
      "source": [
        "print('Prediction probability:\\n',probability_model(x_test[:5]))\n",
        "y_pred = tf.math.argmax(model(x_test[:5]))\n",
        "\n",
        "fig, axes = plt.subplots(1,5,figsize=(10,3), sharex=True, sharey=True)\n",
        "plt.suptitle('Test examples')\n",
        "for i in range(5):\n",
        "  axes[i].imshow(x_test[i], cmap=plt.cm.gray_r)\n",
        "  axes[i].set_title('label: {}, pred:{}'.format(y_test[i], y_pred[i]))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5bM9A_D0wgM2"
      },
      "source": [
        "## Tensorboard"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uIVmK0RkUAwc"
      },
      "source": [
        "%tensorboard --logdir logs/keras"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MP-stroACrYo"
      },
      "source": [
        "## Exercise: Build an MLP model using Sequential\n",
        "\n",
        "The previous sections implemented a linear model.\n",
        "This section implements an MLP models. The code is basically the same except the model is expanded to include some \"hidden\"  non-linear layers. The name \"hidden\" here just means not directly connected to the inputs or outputs."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6SWtkIjhrZwa"
      },
      "source": [
        "These models will contain a few more layers than the linear model:\n",
        "\n",
        "* The flattening layer\n",
        "* Two hidden, nonlinear, `Dense` layers using the `relu` nonlinearity.\n",
        "* A linear single-output layer.\n",
        "\n",
        "Train the model by using the same training procedure above."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vk1XG_aHCzjE"
      },
      "source": [
        "#TODO"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y5KxlH73Zmfh"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}