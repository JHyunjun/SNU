{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.10"
    },
    "colab": {
      "name": "220802_현대차AI_KoGPT실습.ipynb의 사본",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "37243e166337447c96c6ab3662790b15": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_59ecb2bf49134cfda3413d1fc5093e10",
              "IPY_MODEL_39fb081909e24342b4c4098bfd54e41d",
              "IPY_MODEL_3dc43ee8a1854f3da538b153b2143a28"
            ],
            "layout": "IPY_MODEL_cca53747d4e143ea8c225f6fd64e538e"
          }
        },
        "59ecb2bf49134cfda3413d1fc5093e10": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_84fea7a87ac1461c9318364353c30308",
            "placeholder": "​",
            "style": "IPY_MODEL_81236781885d434cbf635d9af1e096f3",
            "value": "Downloading tokenizer.json: 100%"
          }
        },
        "39fb081909e24342b4c4098bfd54e41d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_68a444edee704fd3af8037864dad4132",
            "max": 2825034,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_bb5cbf685a784a42987011a28bf1c504",
            "value": 2825034
          }
        },
        "3dc43ee8a1854f3da538b153b2143a28": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1061821cfac44d8eaa3d98d5e41f3d23",
            "placeholder": "​",
            "style": "IPY_MODEL_96fd0dfb4f004cf591008df4c09259c3",
            "value": " 2.69M/2.69M [00:00&lt;00:00, 22.1MB/s]"
          }
        },
        "cca53747d4e143ea8c225f6fd64e538e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "84fea7a87ac1461c9318364353c30308": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "81236781885d434cbf635d9af1e096f3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "68a444edee704fd3af8037864dad4132": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bb5cbf685a784a42987011a28bf1c504": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "1061821cfac44d8eaa3d98d5e41f3d23": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "96fd0dfb4f004cf591008df4c09259c3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ed54288bb5a44601996fcdff8af4bf6c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_454c3f7de59f4112a59ccad713540119",
              "IPY_MODEL_4577508fe0944ca5a8eb36ed2d3bf097",
              "IPY_MODEL_020f0eb821fa49a08c7e676978c46efb"
            ],
            "layout": "IPY_MODEL_43a727e251054edfbdfa228f6fce229b"
          }
        },
        "454c3f7de59f4112a59ccad713540119": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_cbd5d44f4ee0475fa8b51c1098b2eacd",
            "placeholder": "​",
            "style": "IPY_MODEL_1959e7841aa24523aa5c3e8c819b77b2",
            "value": "Downloading config.json: 100%"
          }
        },
        "4577508fe0944ca5a8eb36ed2d3bf097": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9df8ac61cc554ba8a6bc91948af64f7d",
            "max": 1000,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_c26efb72d59f4912a2848cb1f2bc7b65",
            "value": 1000
          }
        },
        "020f0eb821fa49a08c7e676978c46efb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f7f445ef73a344e6a87f111e1e3168b0",
            "placeholder": "​",
            "style": "IPY_MODEL_b2c8cef82faa4f0fb426b35aaec09e9c",
            "value": " 0.98k/0.98k [00:00&lt;00:00, 31.0kB/s]"
          }
        },
        "43a727e251054edfbdfa228f6fce229b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cbd5d44f4ee0475fa8b51c1098b2eacd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1959e7841aa24523aa5c3e8c819b77b2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9df8ac61cc554ba8a6bc91948af64f7d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c26efb72d59f4912a2848cb1f2bc7b65": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "f7f445ef73a344e6a87f111e1e3168b0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b2c8cef82faa4f0fb426b35aaec09e9c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "781bb428c95349e2b0bf80981c6b7869": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_77127999751343b89bd0e3cda86156a7",
              "IPY_MODEL_dabf01777def44a9bb7071d0bcb98338",
              "IPY_MODEL_8425cb75a3fa4424b0f6b4e7917e06c6"
            ],
            "layout": "IPY_MODEL_4a213f3185cb473184dabdc01d16278b"
          }
        },
        "77127999751343b89bd0e3cda86156a7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_cc67f43c11234878b52b7f720277aff2",
            "placeholder": "​",
            "style": "IPY_MODEL_9057e8142cf845fd86501f33992c01b4",
            "value": "Downloading pytorch_model.bin: 100%"
          }
        },
        "dabf01777def44a9bb7071d0bcb98338": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e94ed09971c647cfb6179a9f66fc8f61",
            "max": 513302779,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_5bf7dfcf0a87457a9fceaef1d6fb1a1a",
            "value": 513302779
          }
        },
        "8425cb75a3fa4424b0f6b4e7917e06c6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a8e446db24dd48f4ae611a1b477507aa",
            "placeholder": "​",
            "style": "IPY_MODEL_ded2198665814747aaf936c70daff277",
            "value": " 490M/490M [00:18&lt;00:00, 25.2MB/s]"
          }
        },
        "4a213f3185cb473184dabdc01d16278b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cc67f43c11234878b52b7f720277aff2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9057e8142cf845fd86501f33992c01b4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e94ed09971c647cfb6179a9f66fc8f61": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5bf7dfcf0a87457a9fceaef1d6fb1a1a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "a8e446db24dd48f4ae611a1b477507aa": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ded2198665814747aaf936c70daff277": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/JHyunjun/SNU/blob/main/KoGPT2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z2LGcoawrlQ7"
      },
      "source": [
        "# 0. Install Packages"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9xwaztFKrmDt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d5ac0488-8e2d-4a44-a61d-cc6d9b282518"
      },
      "source": [
        "!pip install transformers"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting transformers\n",
            "  Downloading transformers-4.21.0-py3-none-any.whl (4.7 MB)\n",
            "\u001b[K     |████████████████████████████████| 4.7 MB 30.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.64.0)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.12.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (21.3)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.21.6)\n",
            "Collecting pyyaml>=5.1\n",
            "  Downloading PyYAML-6.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (596 kB)\n",
            "\u001b[K     |████████████████████████████████| 596 kB 63.9 MB/s \n",
            "\u001b[?25hCollecting tokenizers!=0.11.3,<0.13,>=0.11.1\n",
            "  Downloading tokenizers-0.12.1-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (6.6 MB)\n",
            "\u001b[K     |████████████████████████████████| 6.6 MB 52.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.7.1)\n",
            "Collecting huggingface-hub<1.0,>=0.1.0\n",
            "  Downloading huggingface_hub-0.8.1-py3-none-any.whl (101 kB)\n",
            "\u001b[K     |████████████████████████████████| 101 kB 12.6 MB/s \n",
            "\u001b[?25hRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2022.6.2)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0,>=0.1.0->transformers) (4.1.1)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers) (3.0.9)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.8.1)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2022.6.15)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n",
            "Installing collected packages: pyyaml, tokenizers, huggingface-hub, transformers\n",
            "  Attempting uninstall: pyyaml\n",
            "    Found existing installation: PyYAML 3.13\n",
            "    Uninstalling PyYAML-3.13:\n",
            "      Successfully uninstalled PyYAML-3.13\n",
            "Successfully installed huggingface-hub-0.8.1 pyyaml-6.0 tokenizers-0.12.1 transformers-4.21.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2TQx6kl-rkdM"
      },
      "source": [
        "# 1. Import Packages"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YuKXZmdcrkdS"
      },
      "source": [
        " - 본 실습에 필요한 패키지들을 불러옵니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fR-OY7uhrkdS"
      },
      "source": [
        "from transformers import GPT2Model\n",
        "from transformers import GPT2LMHeadModel\n",
        "from transformers import PreTrainedTokenizerFast\n",
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import urllib\n",
        "import pandas as pd"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UvObBbHnrkdT"
      },
      "source": [
        "# 2. KoGPT2 Tokenizer"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PEiF3thorkdU"
      },
      "source": [
        " - 사전 학습된 KoGPT2 Tokenizer를 불러옵니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mn3NQZyrrkdV",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 193,
          "referenced_widgets": [
            "37243e166337447c96c6ab3662790b15",
            "59ecb2bf49134cfda3413d1fc5093e10",
            "39fb081909e24342b4c4098bfd54e41d",
            "3dc43ee8a1854f3da538b153b2143a28",
            "cca53747d4e143ea8c225f6fd64e538e",
            "84fea7a87ac1461c9318364353c30308",
            "81236781885d434cbf635d9af1e096f3",
            "68a444edee704fd3af8037864dad4132",
            "bb5cbf685a784a42987011a28bf1c504",
            "1061821cfac44d8eaa3d98d5e41f3d23",
            "96fd0dfb4f004cf591008df4c09259c3",
            "ed54288bb5a44601996fcdff8af4bf6c",
            "454c3f7de59f4112a59ccad713540119",
            "4577508fe0944ca5a8eb36ed2d3bf097",
            "020f0eb821fa49a08c7e676978c46efb",
            "43a727e251054edfbdfa228f6fce229b",
            "cbd5d44f4ee0475fa8b51c1098b2eacd",
            "1959e7841aa24523aa5c3e8c819b77b2",
            "9df8ac61cc554ba8a6bc91948af64f7d",
            "c26efb72d59f4912a2848cb1f2bc7b65",
            "f7f445ef73a344e6a87f111e1e3168b0",
            "b2c8cef82faa4f0fb426b35aaec09e9c"
          ]
        },
        "outputId": "6a381f69-f91f-469d-a67f-0156b6e79c21"
      },
      "source": [
        "tokenizer = PreTrainedTokenizerFast.from_pretrained(\"skt/kogpt2-base-v2\", bos_token='</s>', eos_token='</s>', unk_token='<unk>', pad_token='<pad>', mask_token='<mask>', padding_side='right') \n",
        "sample_text = \"근육이 커지기 위해서는\"\n",
        "\n",
        "tokens = tokenizer.tokenize(sample_text)\n",
        "token_ids = tokenizer.encode(sample_text)\n",
        "\n",
        "print(f' Sentence: {sample_text}')\n",
        "print(f'   Tokens: {tokens}')\n",
        "print(f'Token IDs: {token_ids}')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading tokenizer.json:   0%|          | 0.00/2.69M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "37243e166337447c96c6ab3662790b15"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading config.json:   0%|          | 0.00/0.98k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "ed54288bb5a44601996fcdff8af4bf6c"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
            "The tokenizer class you load from this checkpoint is 'GPT2Tokenizer'. \n",
            "The class this function is called from is 'PreTrainedTokenizerFast'.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Sentence: 근육이 커지기 위해서는\n",
            "   Tokens: ['▁근육이', '▁커', '지기', '▁위해서는']\n",
            "Token IDs: [33245, 10114, 12748, 11357]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Iyd2Ya1RrkdW"
      },
      "source": [
        "# 3. KoGPT2 Models"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q7O35G28rkdW"
      },
      "source": [
        " - GPT2Model과 GPT2LMHeadModel을 불러옵니다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vqeeLgoQrkdW"
      },
      "source": [
        "## 3-1. GPT2Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YvrfHXB6rkdX"
      },
      "source": [
        " - GPT2Model은 hidden state를 출력합니다.\n",
        " \n",
        " - 본 예제에서는 네 개의 토큰에 대한 768차원의 벡터가 도출됩니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NiWFyvYLrkdX",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 144,
          "referenced_widgets": [
            "781bb428c95349e2b0bf80981c6b7869",
            "77127999751343b89bd0e3cda86156a7",
            "dabf01777def44a9bb7071d0bcb98338",
            "8425cb75a3fa4424b0f6b4e7917e06c6",
            "4a213f3185cb473184dabdc01d16278b",
            "cc67f43c11234878b52b7f720277aff2",
            "9057e8142cf845fd86501f33992c01b4",
            "e94ed09971c647cfb6179a9f66fc8f61",
            "5bf7dfcf0a87457a9fceaef1d6fb1a1a",
            "a8e446db24dd48f4ae611a1b477507aa",
            "ded2198665814747aaf936c70daff277"
          ]
        },
        "outputId": "509aeecc-3405-4bee-a2bd-9092ece593d4"
      },
      "source": [
        "gpt2_model = GPT2Model.from_pretrained('skt/kogpt2-base-v2')\n",
        "hidden_states = gpt2_model(torch.tensor([token_ids]))\n",
        "last_hidden_state = hidden_states[0]\n",
        "print(last_hidden_state.shape) # 1 : Sentence갯수, 4 : Token의 갯수(근육이,커,지기,위해서는), 768 : 768차원의 벡터로 표현"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading pytorch_model.bin:   0%|          | 0.00/490M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "781bb428c95349e2b0bf80981c6b7869"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at skt/kogpt2-base-v2 were not used when initializing GPT2Model: ['lm_head.weight']\n",
            "- This IS expected if you are initializing GPT2Model from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing GPT2Model from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([1, 4, 768])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PUbrSbg9rkdX"
      },
      "source": [
        "## 3-2. GPT2LMHeadModel"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KM2GGr6prkdX"
      },
      "source": [
        " - GPT2LMHead는 next word prediction을 출력합니다.\n",
        " \n",
        " - 본 예제에서는 네 개의 토큰에 대한 51200 차원의 단어 확률 분포가 도출됩니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cFyDm2aprkdY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1c5280f9-9278-4bbc-e27c-81ff341dc84f"
      },
      "source": [
        "gpt2lm_model = GPT2LMHeadModel.from_pretrained('skt/kogpt2-base-v2')\n",
        "outputs = gpt2lm_model(torch.tensor([token_ids]))\n",
        "next_word_predictions = outputs[0]\n",
        "print(next_word_predictions.shape) #51200 : Vocab size"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([1, 4, 51200])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L2hAXUowrkdY"
      },
      "source": [
        " - 단어 확률 분포에 대해 argmax를 취해 가장 높은 확률을 보이는 단어를 찾습니다.\n",
        " \n",
        " - 본 예제에서는 \"무엇보다\" 라는 단어가 가장 높은 확률을 나타냅니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MXKCYYAIrkdY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ce87cb5a-7bca-4839-b260-9af3e4db80fe"
      },
      "source": [
        "next_word_distribution = next_word_predictions[0, -1, :]\n",
        "next_word_id = torch.argmax(next_word_distribution) # Predict한값중 가장 Max값을 뽑아서 Return (INDEX)\n",
        "next_word = tokenizer.decode(next_word_id) # 다음에 도출될 단어는 Above INDEX에 해당하는 단어다\n",
        "\n",
        "print(f'Next word: {next_word}') # 근육이 커지기 위해서는 -> 무엇보다00"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Next word: 무엇보다\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dm63zr0yrkdZ"
      },
      "source": [
        "# 4. Text Generation Examples (Pre-trained model)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eC7r6SZorkdZ"
      },
      "source": [
        " - 두 가지 Text Generation 방법을 실험해봅니다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NSAms2NyrkdZ"
      },
      "source": [
        "## 4-1. Greedy Search"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Nzw0MSrhrkdZ"
      },
      "source": [
        " - Greedy Search는 가장 높은 확률의 단어를 Greedy하게 찾는 방식으로 텍스트를 생성합니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "DQcKnXhUrkdZ"
      },
      "source": [
        "gen_ids = gpt2lm_model.generate(torch.tensor([token_ids]),\n",
        "                           max_length=127,\n",
        "                           repetition_penalty=2.0,\n",
        "                           )\n",
        "\n",
        "generated = tokenizer.decode(gen_ids[0,:].tolist())\n",
        "print(generated)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hB3dzvRRrkda"
      },
      "source": [
        "## 4-2. Beam Search"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VYeC4nggrkda"
      },
      "source": [
        " - Beam Search는 매 step마다 num_beams 개 만큼의 Top word selection path를 찾습니다.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2NxnOmsg1viV"
      },
      "source": [
        "gen_ids = gpt2lm_model.generate(torch.tensor([token_ids]),\n",
        "                           max_length=127,\n",
        "                           repetition_penalty=2.0,\n",
        "                           num_beams=5, \n",
        "                           )\n",
        "\n",
        "generated = tokenizer.decode(gen_ids[0,:].tolist())\n",
        "print(generated)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EeNelLxerkda"
      },
      "source": [
        "# 5. Fine tunning (Naver Movie review)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t4MoKU6nrkda"
      },
      "source": [
        " - 네이버 영화 리뷰데이터를 활용하여 모델을 Fine Tuning 합니다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mREdF7iarkda"
      },
      "source": [
        "## 5-1. Get Datasets"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gJre_mPgrkda"
      },
      "source": [
        " - github으로부터 네이버 영화 리뷰데이터를 요청하여 내 pc에 저장합니다.\n",
        " \n",
        " - 데이터의 크기가 너무 큰 관계로, 본 실험에서는 테스트 데이터 셋만을 활용하여 모델을 학습시킵니다. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xUdSUHaRrkdb"
      },
      "source": [
        "def get_naver_review_examples():\n",
        "    #urllib.request.urlretrieve(\"https://raw.githubusercontent.com/e9t/nsmc/master/ratings_train.txt\", filename=\"ratings_train.txt\")\n",
        "    urllib.request.urlretrieve(\"https://raw.githubusercontent.com/e9t/nsmc/master/ratings_test.txt\", filename=\"ratings_test.txt\")\n",
        "\n",
        "    #train_data = pd.read_table('ratings_train.txt')\n",
        "    test_data = pd.read_table('ratings_test.txt')\n",
        "    \n",
        "    return test_data"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9y-DCJAki786"
      },
      "source": [
        "naver_data = get_naver_review_examples()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zEw-UUV6i9Z-"
      },
      "source": [
        "naver_data"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ljJUSVn3rkdb"
      },
      "source": [
        " - Dataset Loader를 정의합니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NmEdH-fdrkdb"
      },
      "source": [
        "class NaverReviewDataset(Dataset):\n",
        "    def __init__(self, texts, labels, tokenizer, max_len):\n",
        "        self.texts = texts\n",
        "        self.labels = labels\n",
        "        self.tokenizer = tokenizer\n",
        "        self.max_len = max_len\n",
        "\n",
        "    def __getitem__(self, item):\n",
        "        text = str(self.texts[item])\n",
        "        label = self.labels[item]\n",
        "\n",
        "        encoding = self.tokenizer.encode_plus(\n",
        "          text,\n",
        "          add_special_tokens=True,\n",
        "          max_length=self.max_len,\n",
        "          return_token_type_ids=False,\n",
        "          padding='max_length',\n",
        "          return_attention_mask=True,\n",
        "          return_tensors='pt',\n",
        "          truncation=True,\n",
        "        )\n",
        "\n",
        "        return {\n",
        "          'text': text,\n",
        "          'input_ids': encoding['input_ids'].flatten(),\n",
        "          'attention_mask': encoding['attention_mask'].flatten(),\n",
        "          'labels': torch.tensor(label, dtype=torch.long)\n",
        "        }\n",
        "    \n",
        "    def __len__(self):\n",
        "        return len(self.texts)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XUcXquqfjZAn"
      },
      "source": [
        "dataset = NaverReviewDataset(naver_data['document'], naver_data['label'], tokenizer, 100)\n",
        "train_set, valid_set, test_set = torch.utils.data.random_split(dataset, [40000, 5000, 5000])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_set[0]"
      ],
      "metadata": {
        "id": "RrkzJ8KroI4K",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "679ec397-cb1e-411c-9081-8dd57bbfd710"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0]),\n",
              " 'input_ids': tensor([ 9094,  8148,  7777,  8393, 13897,  7983,  7812, 14558,     3,     3,\n",
              "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3,\n",
              "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3,\n",
              "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3,\n",
              "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3,\n",
              "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3,\n",
              "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3,\n",
              "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3,\n",
              "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3,\n",
              "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3]),\n",
              " 'labels': tensor(1),\n",
              " 'text': '내인생최고의액션영화'}"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SHXFcBEerkdb"
      },
      "source": [
        "batch_size = 8\n",
        "\n",
        "train_dataloader = DataLoader(train_set, batch_size=batch_size,\n",
        "                        shuffle=True)\n",
        "\n",
        "valid_dataloader = DataLoader(valid_set, batch_size=batch_size,\n",
        "                        shuffle=True)\n",
        "\n",
        "test_dataloader = DataLoader(test_set, batch_size=batch_size,\n",
        "                        shuffle=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sample_data = next(iter(test_dataloader))\n",
        "sample_data"
      ],
      "metadata": {
        "id": "KzN_EHt7op82",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0cb5bd16-d4e4-47d2-9e31-f8d51972f3f1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0],\n",
              "         [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0],\n",
              "         [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0],\n",
              "         [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0],\n",
              "         [1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0],\n",
              "         [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0],\n",
              "         [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0],\n",
              "         [1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0]]),\n",
              " 'input_ids': tensor([[ 9063, 10418, 10278,  7965, 10765, 10891,  8696,  6853,  8041,  8006,\n",
              "          34510, 20861,  9097,  9822,  9063,  8072,  8139, 27120, 10765,     3,\n",
              "              3,     3,     3,     3,     3,     3,     3,     3,     3,     3,\n",
              "              3,     3,     3,     3,     3,     3,     3,     3,     3,     3,\n",
              "              3,     3,     3,     3,     3,     3,     3,     3,     3,     3,\n",
              "              3,     3,     3,     3,     3,     3,     3,     3,     3,     3,\n",
              "              3,     3,     3,     3,     3,     3,     3,     3,     3,     3,\n",
              "              3,     3,     3,     3,     3,     3,     3,     3,     3,     3,\n",
              "              3,     3,     3,     3,     3,     3,     3,     3,     3,     3,\n",
              "              3,     3,     3,     3,     3,     3,     3,     3,     3,     3],\n",
              "         [28734,  7312,  9269, 14558,   739,   605,   605,   605,   605,  9226,\n",
              "          20486,  9427, 10056,  7898,  7182,   739,   605,   605,   605,   605,\n",
              "              3,     3,     3,     3,     3,     3,     3,     3,     3,     3,\n",
              "              3,     3,     3,     3,     3,     3,     3,     3,     3,     3,\n",
              "              3,     3,     3,     3,     3,     3,     3,     3,     3,     3,\n",
              "              3,     3,     3,     3,     3,     3,     3,     3,     3,     3,\n",
              "              3,     3,     3,     3,     3,     3,     3,     3,     3,     3,\n",
              "              3,     3,     3,     3,     3,     3,     3,     3,     3,     3,\n",
              "              3,     3,     3,     3,     3,     3,     3,     3,     3,     3,\n",
              "              3,     3,     3,     3,     3,     3,     3,     3,     3,     3],\n",
              "         [12201, 10607,  8008,  9230, 29446, 31354, 32322,  8185,  9354,  9292,\n",
              "          10468, 25793,  7235, 11805,  7898,  9016,  9018, 26095, 11382, 10135,\n",
              "           7235,  9564,  9337, 16029, 15319, 10805,  7235,  9564, 25218, 32694,\n",
              "          16437, 15016,  6824,  9306, 10584, 10322, 33435, 12371, 16173, 10954,\n",
              "           9848, 35158, 13742,  7235, 10004, 13074, 12371, 50206, 10390, 11223,\n",
              "          11335, 10175,  9329,  9658,     3,     3,     3,     3,     3,     3,\n",
              "              3,     3,     3,     3,     3,     3,     3,     3,     3,     3,\n",
              "              3,     3,     3,     3,     3,     3,     3,     3,     3,     3,\n",
              "              3,     3,     3,     3,     3,     3,     3,     3,     3,     3,\n",
              "              3,     3,     3,     3,     3,     3,     3,     3,     3,     3],\n",
              "         [29205,  8170,  7584,  8015,  9016,   394, 28076,  7092,  7162,  7183,\n",
              "           8539,  8263,  7596, 20480,  9122,  7354,  8811, 11867, 17582,   389,\n",
              "           8146, 10584, 19795,  7652,  9317,  8237,  7162,  8239,     3,     3,\n",
              "              3,     3,     3,     3,     3,     3,     3,     3,     3,     3,\n",
              "              3,     3,     3,     3,     3,     3,     3,     3,     3,     3,\n",
              "              3,     3,     3,     3,     3,     3,     3,     3,     3,     3,\n",
              "              3,     3,     3,     3,     3,     3,     3,     3,     3,     3,\n",
              "              3,     3,     3,     3,     3,     3,     3,     3,     3,     3,\n",
              "              3,     3,     3,     3,     3,     3,     3,     3,     3,     3,\n",
              "              3,     3,     3,     3,     3,     3,     3,     3,     3,     3],\n",
              "         [13248, 10609, 50822, 19684,  7478,     3,     3,     3,     3,     3,\n",
              "              3,     3,     3,     3,     3,     3,     3,     3,     3,     3,\n",
              "              3,     3,     3,     3,     3,     3,     3,     3,     3,     3,\n",
              "              3,     3,     3,     3,     3,     3,     3,     3,     3,     3,\n",
              "              3,     3,     3,     3,     3,     3,     3,     3,     3,     3,\n",
              "              3,     3,     3,     3,     3,     3,     3,     3,     3,     3,\n",
              "              3,     3,     3,     3,     3,     3,     3,     3,     3,     3,\n",
              "              3,     3,     3,     3,     3,     3,     3,     3,     3,     3,\n",
              "              3,     3,     3,     3,     3,     3,     3,     3,     3,     3,\n",
              "              3,     3,     3,     3,     3,     3,     3,     3,     3,     3],\n",
              "         [39061, 10780, 15413, 11379,  9668, 29524,  8153,  8146,  9069,  7788,\n",
              "           9306, 19221, 12102, 10165,  6958, 13041,  6872, 12226, 13358,  8017,\n",
              "           8006, 25856, 10364, 14967, 25890, 24011, 12371, 12011, 25856,     3,\n",
              "              3,     3,     3,     3,     3,     3,     3,     3,     3,     3,\n",
              "              3,     3,     3,     3,     3,     3,     3,     3,     3,     3,\n",
              "              3,     3,     3,     3,     3,     3,     3,     3,     3,     3,\n",
              "              3,     3,     3,     3,     3,     3,     3,     3,     3,     3,\n",
              "              3,     3,     3,     3,     3,     3,     3,     3,     3,     3,\n",
              "              3,     3,     3,     3,     3,     3,     3,     3,     3,     3,\n",
              "              3,     3,     3,     3,     3,     3,     3,     3,     3,     3],\n",
              "         [15538, 28365,  6830,  9022, 14509,   389, 16971, 12155, 11244, 10415,\n",
              "              3,     3,     3,     3,     3,     3,     3,     3,     3,     3,\n",
              "              3,     3,     3,     3,     3,     3,     3,     3,     3,     3,\n",
              "              3,     3,     3,     3,     3,     3,     3,     3,     3,     3,\n",
              "              3,     3,     3,     3,     3,     3,     3,     3,     3,     3,\n",
              "              3,     3,     3,     3,     3,     3,     3,     3,     3,     3,\n",
              "              3,     3,     3,     3,     3,     3,     3,     3,     3,     3,\n",
              "              3,     3,     3,     3,     3,     3,     3,     3,     3,     3,\n",
              "              3,     3,     3,     3,     3,     3,     3,     3,     3,     3,\n",
              "              3,     3,     3,     3,     3,     3,     3,     3,     3,     3],\n",
              "         [ 9130,  7461,  8467,  7585,     3,     3,     3,     3,     3,     3,\n",
              "              3,     3,     3,     3,     3,     3,     3,     3,     3,     3,\n",
              "              3,     3,     3,     3,     3,     3,     3,     3,     3,     3,\n",
              "              3,     3,     3,     3,     3,     3,     3,     3,     3,     3,\n",
              "              3,     3,     3,     3,     3,     3,     3,     3,     3,     3,\n",
              "              3,     3,     3,     3,     3,     3,     3,     3,     3,     3,\n",
              "              3,     3,     3,     3,     3,     3,     3,     3,     3,     3,\n",
              "              3,     3,     3,     3,     3,     3,     3,     3,     3,     3,\n",
              "              3,     3,     3,     3,     3,     3,     3,     3,     3,     3,\n",
              "              3,     3,     3,     3,     3,     3,     3,     3,     3,     3]]),\n",
              " 'labels': tensor([0, 1, 1, 0, 0, 1, 0, 0]),\n",
              " 'text': ['나탈리아 와아.... 바람핀거였어..... 확실한 영상이 나왓음 했는데....',\n",
              "  '어렸을때 본영화 ㅋㅋㅋㅋ 간만에 다시 보고싶다 ㅋㅋㅋㅋ',\n",
              "  '우선 아이언 스카이 카페 매니저로서 10점을 너무나도 주고싶다. 이 영화를 위해서 시간도 많이 할애를 하였고, 노력도 많이 했다. 단, 불법 공유가 다른 영화들에 비해서 너무 빨리 이루어져 버렸고 관념도 우리나라와는 너무달라 흥행을 못한 이유라고 생각',\n",
              "  '정말재미없다.3시간이넘는닥터지바고도 거뜬히 보는 내가.이 영화 끝까지보다가죽는줄',\n",
              "  '서정적이고 난해한 스토리',\n",
              "  '남자의 마지막말을 듣는데 감정이입이 되서 다른 우주의 나는 이런기분이겠구나 싶었어요. 학생시절 영화의 색이 너무 좋아요.',\n",
              "  '오직 혐오감 그 자체. 니콜라스 케이지',\n",
              "  '4류코믹']}"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vMj2_y_Zrkdc"
      },
      "source": [
        "## 5-2. Model Settings"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MoEvXVKbrkdc"
      },
      "source": [
        " - Model의 환경을 설정합니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wn3YXDc5rkdc"
      },
      "source": [
        "gpt2lm_model.train()\n",
        "\n",
        "learning_rate = 1e-5\n",
        "criterion = torch.nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(gpt2lm_model.parameters(), lr=learning_rate)\n",
        "\n",
        "device = 'cuda'\n",
        "\n",
        "epochs = 10\n",
        "count = 0"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sample_inputs = sample_data['input_ids'].to(device)\n",
        "sample_outputs = gpt2lm_model(sample_inputs, labels=sample_inputs)"
      ],
      "metadata": {
        "id": "eZaZLaCqph3w",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 367
        },
        "outputId": "0c58e8be-4d7e-440a-ad0b-e6cab5a153ea"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-17-2a3761eaa1dd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0msample_inputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msample_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'input_ids'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0msample_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgpt2lm_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msample_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_inputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1128\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1131\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1132\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/transformers/models/gpt2/modeling_gpt2.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, past_key_values, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, labels, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m   1069\u001b[0m             \u001b[0moutput_attentions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_attentions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1070\u001b[0m             \u001b[0moutput_hidden_states\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_hidden_states\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1071\u001b[0;31m             \u001b[0mreturn_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreturn_dict\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1072\u001b[0m         )\n\u001b[1;32m   1073\u001b[0m         \u001b[0mhidden_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtransformer_outputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1128\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1131\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1132\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/transformers/models/gpt2/modeling_gpt2.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, past_key_values, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m    842\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    843\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0minputs_embeds\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 844\u001b[0;31m             \u001b[0minputs_embeds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwte\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    845\u001b[0m         \u001b[0mposition_embeds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwpe\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mposition_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    846\u001b[0m         \u001b[0mhidden_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minputs_embeds\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mposition_embeds\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1128\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1131\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1132\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/sparse.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    158\u001b[0m         return F.embedding(\n\u001b[1;32m    159\u001b[0m             \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpadding_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_norm\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 160\u001b[0;31m             self.norm_type, self.scale_grad_by_freq, self.sparse)\n\u001b[0m\u001b[1;32m    161\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    162\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36membedding\u001b[0;34m(input, weight, padding_idx, max_norm, norm_type, scale_grad_by_freq, sparse)\u001b[0m\n\u001b[1;32m   2197\u001b[0m         \u001b[0;31m# remove once script supports set_grad_enabled\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2198\u001b[0m         \u001b[0m_no_grad_embedding_renorm_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_norm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnorm_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2199\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membedding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpadding_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscale_grad_by_freq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msparse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2200\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2201\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: Expected all tensors to be on the same device, but found at least two devices, cpu and cuda:0! (when checking argument for argument index in method wrapper__index_select)"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sample_outputs['loss']"
      ],
      "metadata": {
        "id": "dSAgM2yZp78r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m15km-r2rkdc"
      },
      "source": [
        "## 5-3. Model Training"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "58yCR-xarkdd"
      },
      "source": [
        " - Model의 학습을 시작합니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "iUoZ4cP8rkdd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d33ae402-da27-4ac4-f6f3-f56d1699ed1e"
      },
      "source": [
        "tot_train_loss = 0.0\n",
        "tot_valid_loss = 0.0\n",
        "prev_valid_loss = 10000\n",
        "\n",
        "print('KoGPT-2 Training Start!')\n",
        "\n",
        "for epoch in range(epochs):\n",
        "    for batch, train_data in enumerate(train_dataloader):\n",
        "        # train data를 모델에 입력하여 출력 값을 얻습니다.\n",
        "        gpt2lm_model.to(device)\n",
        "        train_inputs = train_data['input_ids'].to(device)\n",
        "        train_outputs = gpt2lm_model(train_inputs, labels=train_inputs) # train_outputs = (train_loss, train_logits, train_past_hidden_states)\n",
        "        \n",
        "        train_loss, _ = train_outputs[:2]\n",
        "        \n",
        "        # valid data를 모델에 입력하여 출력 값을 얻습니다.\n",
        "            \n",
        "        valid_data = next(iter(valid_dataloader))\n",
        "\n",
        "        gpt2lm_model.to(device)\n",
        "        valid_inputs = valid_data['input_ids'].to(device)     \n",
        "        valid_outputs = gpt2lm_model(valid_inputs, labels=valid_inputs)\n",
        "        \n",
        "        valid_loss, _ = valid_outputs[:2]\n",
        "        \n",
        "        gpt2lm_model.to(device)\n",
        "        \n",
        "        # train loss를 토대로 모델을 학습합니다.\n",
        "        optimizer.zero_grad()\n",
        "        train_loss.backward()\n",
        "        optimizer.step()\n",
        "        \n",
        "        tot_train_loss += train_loss.item()\n",
        "        tot_valid_loss += valid_loss.item()\n",
        "               \n",
        "        # 200 batch 마다 학습 상황을 화면에 출력합니다.\n",
        "        if count % 200 == 0:\n",
        "            cnt = ((count+1) * batch_size)\n",
        "            current_train_loss = tot_train_loss / cnt\n",
        "            current_valid_loss = tot_valid_loss / cnt\n",
        "            \n",
        "            print(f'epoch : %5d | batch : %5d | train_loss : %.5f | valid_loss : %.5f' %(epoch+1, batch+1, current_train_loss, current_valid_loss))\n",
        "            \n",
        "            tot_train_loss = 0.0\n",
        "            tot_valid_loss = 0.0\n",
        "            \n",
        "            count = 0\n",
        "            \n",
        "            # 이전 valid_loss 보다 현재의 valid_loss가 더 낮을 경우, 모델을 저장합니다.\n",
        "            if prev_valid_loss > current_valid_loss:\n",
        "                prev_valid_loss = current_valid_loss\n",
        "                torch.save(gpt2lm_model.state_dict(), f'./KoGPT-model.pth')\n",
        "        \n",
        "        count += 1"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "KoGPT-2 Training Start!\n",
            "epoch :     1 | batch :     1 | train_loss : 1.20257 | valid_loss : 1.14717\n",
            "epoch :     1 | batch :   201 | train_loss : 0.13113 | valid_loss : 0.13568\n",
            "epoch :     1 | batch :   401 | train_loss : 0.11235 | valid_loss : 0.11800\n",
            "epoch :     1 | batch :   601 | train_loss : 0.11518 | valid_loss : 0.11813\n",
            "epoch :     1 | batch :   801 | train_loss : 0.11103 | valid_loss : 0.11270\n",
            "epoch :     1 | batch :  1001 | train_loss : 0.11254 | valid_loss : 0.11514\n",
            "epoch :     1 | batch :  1201 | train_loss : 0.10805 | valid_loss : 0.10870\n",
            "epoch :     1 | batch :  1401 | train_loss : 0.11006 | valid_loss : 0.11158\n",
            "epoch :     1 | batch :  1601 | train_loss : 0.11023 | valid_loss : 0.11292\n",
            "epoch :     1 | batch :  1801 | train_loss : 0.11231 | valid_loss : 0.10897\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mpX6-BeE9NcR"
      },
      "source": [
        "train_set[5]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yKp_ygcR8VhK"
      },
      "source": [
        "kogpt_load_path = f\"./KoGPT-model.pth\"\n",
        "\n",
        "gpt2lm_model.load_state_dict(torch.load(kogpt_load_path))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xVNd9zhPrkde"
      },
      "source": [
        "gpt2lm_model.to(device)\n",
        "\n",
        "sample_text = \"정말 재미\"\n",
        "\n",
        "tokens = tokenizer.tokenize(sample_text)\n",
        "token_ids = tokenizer.encode(sample_text)\n",
        "\n",
        "gen_ids = gpt2lm_model.generate(torch.tensor([token_ids]).to(device),\n",
        "                           max_length=127,\n",
        "                           repetition_penalty=1.0,\n",
        "                           num_beams=5)\n",
        "\n",
        "generated = tokenizer.decode(gen_ids[0,:].tolist())\n",
        "print(generated)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7Fs-HK23-BH4"
      },
      "source": [
        "import re\n",
        "\n",
        "p = re.compile('<pad>')\n",
        "re.sub(p, '', generated)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kiDq9EVFrkde"
      },
      "source": [
        "# 6. Fine Tuning 2 (Classification Task)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j4VEfnherkde"
      },
      "source": [
        " - Dateset을 가져옵니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9Xcj-OEirkde"
      },
      "source": [
        "tokenizer = PreTrainedTokenizerFast.from_pretrained(\"skt/kogpt2-base-v2\", bos_token='</s>', eos_token='</s>', unk_token='<unk>', pad_token='<pad>', mask_token='<mask>', padding_side='left') "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zzabGZvIrkde"
      },
      "source": [
        "batch_size = 16\n",
        "\n",
        "naver_data = get_naver_review_examples()\n",
        "\n",
        "dataset = NaverReviewDataset(naver_data['document'], naver_data['label'], tokenizer, 100)\n",
        "train_set, valid_set, test_set = torch.utils.data.random_split(dataset, [40000, 5000, 5000])\n",
        "\n",
        "train_dataloader = DataLoader(train_set, batch_size=batch_size,\n",
        "                        shuffle=True)\n",
        "\n",
        "valid_dataloader = DataLoader(valid_set, batch_size=batch_size,\n",
        "                        shuffle=True)\n",
        "\n",
        "test_dataloader = DataLoader(test_set, batch_size=batch_size,\n",
        "                        shuffle=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HJPwD9Xerkde"
      },
      "source": [
        " - GPT Classifier를 정의합니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wod_VKl7rkdf"
      },
      "source": [
        "class GPT2SentimentClassifier(torch.nn.Module):\n",
        "\n",
        "    def __init__(self, n_classes):\n",
        "        super(GPT2SentimentClassifier, self).__init__()\n",
        "\n",
        "        self.gpt_model = GPT2Model.from_pretrained('skt/kogpt2-base-v2')\n",
        "        self.drop = torch.nn.Dropout(p=0.1)\n",
        "        self.out = torch.nn.Linear(self.gpt_model.config.hidden_size, n_classes)\n",
        "\n",
        "    def forward(self, input_ids, attention_mask):\n",
        "        hidden_states = self.gpt_model(\n",
        "          input_ids=input_ids,\n",
        "          attention_mask=attention_mask\n",
        "        )\n",
        "        last_hidden_state = hidden_states[0]\n",
        "        \n",
        "        output = self.drop(last_hidden_state[:, -1, :])\n",
        "\n",
        "        return self.out(output)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zBBgK4LDrkdf"
      },
      "source": [
        " - Model의 환경을 설정합니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KS8te_26rkdf"
      },
      "source": [
        "gpt_clf = GPT2SentimentClassifier(n_classes=1)\n",
        "gpt_clf.train()\n",
        "\n",
        "learning_rate = 5e-5\n",
        "criterion = torch.nn.BCEWithLogitsLoss()\n",
        "optimizer = torch.optim.Adam(gpt_clf.parameters(), lr=learning_rate)\n",
        "\n",
        "device = 'cuda'\n",
        "\n",
        "epochs = 1\n",
        "count = 0"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zu6wBkkgrkdf"
      },
      "source": [
        " - 정확도 계산 함수를 정의합니다. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bLNnDiNgrkdf"
      },
      "source": [
        "def cal_correct_num(predicts, labels):\n",
        "    predicts_ = predicts >= 0.5\n",
        "    correct_num = torch.sum(predicts_ == labels)\n",
        "        \n",
        "    return correct_num"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ad3KaQHCrkdg"
      },
      "source": [
        " - Model의 학습을 시작합니다"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "38LkHRZ1rkdg"
      },
      "source": [
        "tot_train_loss = 0.0\n",
        "tot_valid_loss = 0.0\n",
        "\n",
        "train_correct_num = 0\n",
        "valid_correct_num = 0\n",
        "\n",
        "prev_valid_loss = 10000\n",
        "\n",
        "print('KoGPT-2 Training Start!')\n",
        "\n",
        "for epoch in range(epochs):\n",
        "    for batch, train_data in enumerate(train_dataloader):\n",
        "        # train data를 모델에 입력하여 출력 값을 얻습니다.\n",
        "        gpt_clf.to(device)\n",
        "        train_inputs = train_data['input_ids'].to(device)\n",
        "        train_masks = train_data['attention_mask'].to(device)\n",
        "        train_labels = train_data['labels'].to(device)\n",
        "        \n",
        "        train_outputs = gpt_clf(train_inputs, train_masks)\n",
        "        \n",
        "        train_loss = criterion(train_outputs.view(-1), train_labels.float())\n",
        "        \n",
        "        # valid data를 모델에 입력하여 출력 값을 얻습니다.\n",
        "            \n",
        "        valid_data = next(iter(valid_dataloader))\n",
        "\n",
        "        gpt_clf.to(device)\n",
        "        valid_inputs = valid_data['input_ids'].to(device)    \n",
        "        valid_masks = valid_data['attention_mask'].to(device)\n",
        "        valid_labels = valid_data['labels'].to(device)\n",
        "        \n",
        "        valid_outputs = gpt_clf(valid_inputs, valid_masks)\n",
        "        \n",
        "        valid_loss = criterion(valid_outputs.view(-1), valid_labels.float())\n",
        "        \n",
        "        gpt_clf.to(device)\n",
        "        \n",
        "        # train loss를 토대로 모델을 학습합니다.\n",
        "        optimizer.zero_grad()\n",
        "        train_loss.backward()\n",
        "        optimizer.step()\n",
        "        \n",
        "        tot_train_loss += train_loss.item()\n",
        "        tot_valid_loss += valid_loss.item()\n",
        "        \n",
        "        train_correct_num += cal_correct_num(torch.sigmoid(train_outputs.view(-1)), train_labels.float())\n",
        "        valid_correct_num += cal_correct_num(torch.sigmoid(valid_outputs.view(-1)), valid_labels.float())\n",
        "               \n",
        "        # 200 batch 마다 학습 상황을 화면에 출력합니다.\n",
        "        if count % 200 == 0:\n",
        "            cnt = ((count+1) * batch_size)\n",
        "            current_train_loss = tot_train_loss / cnt\n",
        "            current_valid_loss = tot_valid_loss / cnt\n",
        "            \n",
        "            train_acc = train_correct_num / cnt\n",
        "            valid_acc = valid_correct_num / cnt\n",
        "            \n",
        "            print(f'epoch : %5d | batch : %5d | train_loss : %.5f | valid_loss : %.5f | train_acc : %.5f | valid_acc : %.5f' %(epoch+1, batch+1, current_train_loss, current_valid_loss, train_acc, valid_acc))\n",
        "            \n",
        "            tot_train_loss = 0.0\n",
        "            tot_valid_loss = 0.0\n",
        "            \n",
        "            train_correct_num = 0\n",
        "            valid_correct_num = 0\n",
        "            \n",
        "            count = 0\n",
        "            \n",
        "            # 이전 test_loss 보다 현재의 test_loss가 더 낮을 경우, 모델을 저장합니다.\n",
        "            if prev_valid_loss > current_valid_loss:\n",
        "                prev_valid_loss = current_valid_loss\n",
        "                torch.save(gpt_clf.state_dict(), f'./KoGPT-Classifier-model.pth')\n",
        "        \n",
        "        count += 1"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}