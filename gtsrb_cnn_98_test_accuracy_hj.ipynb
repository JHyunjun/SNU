{
  "metadata": {
    "kernelspec": {
      "language": "python",
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "version": "3.6.4",
      "file_extension": ".py",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "name": "python",
      "mimetype": "text/x-python"
    },
    "colab": {
      "name": "gtsrb-cnn-98-test-accuracy_hj.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/JHyunjun/SNU/blob/main/gtsrb_cnn_98_test_accuracy_hj.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# *Traffic Sign Recognizer - 99% accuracy*"
      ],
      "metadata": {
        "id": "vXZZkqWvnIiR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Importing Required Libraries"
      ],
      "metadata": {
        "id": "Z-JIfPEonIiU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import os\n",
        "import cv2\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from PIL import Image\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from sklearn.metrics import accuracy_score\n",
        "np.random.seed(7)\n",
        "\n",
        "from matplotlib import style\n",
        "style.use('fivethirtyeight')"
      ],
      "metadata": {
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "trusted": true,
        "id": "3SHLjA0HnIiU"
      },
      "execution_count": 113,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oXHv9RY-oih0",
        "outputId": "0d2c734d-56ca-4e3e-f0cf-336f051cd842"
      },
      "execution_count": 114,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "path_to_zip_file = '/content/drive/MyDrive/Colab Notebooks/snu/project/data.zip'\n",
        "directory_to_extract_to = '/content/drive/MyDrive/Colab Notebooks/snu/project/data'\n",
        "\n",
        "import zipfile\n",
        "with zipfile.ZipFile(path_to_zip_file,'r') as zip_ref:\n",
        "  zip_ref.extractall(directory_to_extract_to)\n"
      ],
      "metadata": {
        "id": "21FJvrRrn1ZK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Assigning Path for Dataset"
      ],
      "metadata": {
        "id": "GISQNGJYnIiV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data_dir = '/content/drive/MyDrive/Colab Notebooks/snu/project/data/data'\n",
        "data_dir_test = '/content/drive/MyDrive/Colab Notebooks/snu/project/datafortest'\n",
        "\n",
        "train_path = '/content/drive/MyDrive/Colab Notebooks/snu/project/data/data/Train'\n",
        "test_path = '/content/drive/MyDrive/Colab Notebooks/snu/project/datafortest/Test'\n",
        "\n",
        "# Resizing the images to 40x40x3\n",
        "IMG_HEIGHT = 40\n",
        "IMG_WIDTH = 40\n",
        "channels = 3"
      ],
      "metadata": {
        "trusted": true,
        "id": "7Smx0pElnIiW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.environ['KAGGLE_USERNAME'] = 'hyunjunjang'\n",
        "os.environ['KAGGLE_KEY'] = '63c6ccdb188e6b6557e021a25bf8f37d'"
      ],
      "metadata": {
        "id": "M1MCcARl2eXM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!kaggle datasets download -d meowmeowmeowmeowmeow/gtsrb-german-traffic-sign"
      ],
      "metadata": {
        "id": "PC1hkj7n3KHM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "path_to_zip_file = '/content/gtsrb-german-traffic-sign.zip'\n",
        "directory_to_extract_to = '/content/drive/MyDrive/Colab Notebooks/snu/project/datafortest'\n",
        "\n",
        "import zipfile\n",
        "with zipfile.ZipFile(path_to_zip_file,'r') as zip_ref:\n",
        "  zip_ref.extractall(directory_to_extract_to)"
      ],
      "metadata": {
        "id": "8vBaWwSa3Zvz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Finding Total Classes"
      ],
      "metadata": {
        "id": "UfRo1q12nIiW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "NUM_CATEGORIES = len(os.listdir(train_path))\n",
        "NUM_CATEGORIES"
      ],
      "metadata": {
        "trusted": true,
        "id": "dWRvrqh6nIiX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Label Overview\n",
        "classes = { 0:'Speed limit (20km/h)',\n",
        "            1:'Speed limit (30km/h)', \n",
        "            2:'Speed limit (50km/h)', \n",
        "            3:'Speed limit (60km/h)', \n",
        "            4:'Speed limit (70km/h)', \n",
        "            5:'Speed limit (80km/h)', \n",
        "            6:'End of speed limit (80km/h)', \n",
        "            7:'Speed limit (100km/h)', \n",
        "            8:'Speed limit (120km/h)', \n",
        "            9:'No passing', \n",
        "            10:'No passing veh over 3.5 tons', \n",
        "            11:'Right-of-way at intersection', \n",
        "            12:'Priority road', \n",
        "            13:'Yield', \n",
        "            14:'Stop', \n",
        "            15:'No vehicles', \n",
        "            16:'Veh > 3.5 tons prohibited', \n",
        "            17:'No entry', \n",
        "            18:'General caution', \n",
        "            19:'Dangerous curve left', \n",
        "            20:'Dangerous curve right', \n",
        "            21:'Double curve', \n",
        "            22:'Bumpy road', \n",
        "            23:'Slippery road', \n",
        "            24:'Road narrows on the right', \n",
        "            25:'Road work', \n",
        "            26:'Traffic signals', \n",
        "            27:'Pedestrians', \n",
        "            28:'Children crossing', \n",
        "            29:'Bicycles crossing', \n",
        "            30:'Beware of ice/snow',\n",
        "            31:'Wild animals crossing', \n",
        "            32:'End speed + passing limits', \n",
        "            33:'Turn right ahead', \n",
        "            34:'Turn left ahead', \n",
        "            35:'Ahead only', \n",
        "            36:'Go straight or right', \n",
        "            37:'Go straight or left', \n",
        "            38:'Keep right', \n",
        "            39:'Keep left', \n",
        "            40:'Roundabout mandatory', \n",
        "            41:'End of no passing', \n",
        "            42:'End no passing veh > 3.5 tons' }"
      ],
      "metadata": {
        "trusted": true,
        "id": "nVelM6v4nIiX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Visualizing The Dataset"
      ],
      "metadata": {
        "id": "pbggOhNznIiZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "folders = os.listdir(train_path)\n",
        "\n",
        "train_number = []\n",
        "class_num = []\n",
        "\n",
        "for folder in folders:\n",
        "    train_files = os.listdir(train_path + '/' + folder)\n",
        "    train_number.append(len(train_files))\n",
        "    class_num.append(classes[int(folder)])\n",
        "    \n",
        "# Sorting the dataset on the basis of number of images in each class\n",
        "zipped_lists = zip(train_number, class_num)\n",
        "sorted_pairs = sorted(zipped_lists)\n",
        "tuples = zip(*sorted_pairs)\n",
        "train_number, class_num = [ list(tuple) for tuple in  tuples]\n",
        "\n",
        "# Plotting the number of images in each class\n",
        "plt.figure(figsize=(21,10))  \n",
        "plt.bar(class_num, train_number)\n",
        "plt.xticks(class_num, rotation='vertical')\n",
        "plt.show()"
      ],
      "metadata": {
        "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a",
        "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
        "trusted": true,
        "id": "rH9QblQWnIiZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualizing 25 random images from test data\n",
        "import random\n",
        "from matplotlib.image import imread\n",
        "\n",
        "test = pd.read_csv(data_dir_test + '/Test.csv')\n",
        "imgs = test[\"Path\"].values\n",
        "\n",
        "plt.figure(figsize=(25,25))\n",
        "\n",
        "for i in range(1,26):\n",
        "    plt.subplot(5,5,i)\n",
        "    random_img_path = data_dir_test + '/' + random.choice(imgs)\n",
        "    rand_img = imread(random_img_path)\n",
        "    plt.imshow(rand_img)\n",
        "    plt.grid(b=None)\n",
        "    plt.xlabel(rand_img.shape[1], fontsize = 20)#width of image\n",
        "    plt.ylabel(rand_img.shape[0], fontsize = 20)#height of image\n"
      ],
      "metadata": {
        "trusted": true,
        "id": "wsF8Hz80nIia"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Collecting the Training Data"
      ],
      "metadata": {
        "id": "7N_Z5dpWnIia"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "image_data = []\n",
        "image_labels = []\n",
        "\n",
        "for i in range(NUM_CATEGORIES):\n",
        "    path = data_dir + '/Train/' + str(i)\n",
        "    images = os.listdir(path)\n",
        "\n",
        "    for img in images:\n",
        "        try:\n",
        "            image = cv2.imread(path + '/' + img)\n",
        "            image_fromarray = Image.fromarray(image, 'RGB')\n",
        "            resize_image = image_fromarray.resize((IMG_HEIGHT, IMG_WIDTH))\n",
        "            image_data.append(np.array(resize_image))\n",
        "            image_labels.append(i)\n",
        "        except:\n",
        "            print(\"Error in \" + img)\n",
        "\n",
        "# Changing the list to numpy array\n",
        "image_data = np.array(image_data)\n",
        "image_labels = np.array(image_labels)\n",
        "\n",
        "print(image_data.shape, image_labels.shape)"
      ],
      "metadata": {
        "trusted": true,
        "id": "0foROekwnIib"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Shuffling the training data"
      ],
      "metadata": {
        "id": "tXnadaHVnIib"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "shuffle_indexes = np.arange(image_data.shape[0])\n",
        "np.random.shuffle(shuffle_indexes)\n",
        "image_data = image_data[shuffle_indexes]\n",
        "image_labels = image_labels[shuffle_indexes]"
      ],
      "metadata": {
        "trusted": true,
        "id": "LVou5SLnnIib"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Splitting the data into train and validation set"
      ],
      "metadata": {
        "id": "gTRP9KVnnIib"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_val, y_train, y_val = train_test_split(image_data, image_labels, test_size=0.1, random_state=42, shuffle=True)\n",
        "\n",
        "X_train = X_train/255 \n",
        "X_val = X_val/255\n",
        "\n",
        "print(\"X_train.shape\", X_train.shape)\n",
        "print(\"X_valid.shape\", X_val.shape)\n",
        "print(\"y_train.shape\", y_train.shape)\n",
        "print(\"y_valid.shape\", y_val.shape)"
      ],
      "metadata": {
        "trusted": true,
        "id": "Ys5LHJxunIic"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## One hot encoding the labels"
      ],
      "metadata": {
        "id": "tVVaXDBMnIic"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "y_train = keras.utils.to_categorical(y_train, NUM_CATEGORIES)\n",
        "y_val = keras.utils.to_categorical(y_val, NUM_CATEGORIES)\n",
        "\n",
        "print(y_train.shape)\n",
        "print(y_val.shape)"
      ],
      "metadata": {
        "trusted": true,
        "id": "nrm7YG6KnIic"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Making the model"
      ],
      "metadata": {
        "id": "xKRmhveonIic"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = keras.models.Sequential([    \n",
        "    keras.layers.Conv2D(filters=16*2, kernel_size=(3,3), activation='relu', input_shape=(IMG_HEIGHT,IMG_WIDTH,channels)),\n",
        "    keras.layers.Conv2D(filters=32*2, kernel_size=(3,3), activation='relu'),\n",
        "    keras.layers.MaxPool2D(pool_size=(2, 2)),\n",
        "    keras.layers.BatchNormalization(axis=-1),\n",
        "    \n",
        "    keras.layers.Conv2D(filters=64*2, kernel_size=(3,3), activation='relu'),\n",
        "    keras.layers.Conv2D(filters=128*2, kernel_size=(3,3), activation='relu'),\n",
        "    keras.layers.MaxPool2D(pool_size=(2, 2)),\n",
        "    keras.layers.BatchNormalization(axis=-1),\n",
        "    \n",
        "    keras.layers.Flatten(),\n",
        "    keras.layers.Dense(512*2, activation='relu'),\n",
        "    keras.layers.BatchNormalization(),\n",
        "    keras.layers.Dropout(rate=0.5),\n",
        "    \n",
        "    keras.layers.Dense(43, activation='softmax')\n",
        "])"
      ],
      "metadata": {
        "trusted": true,
        "id": "DXPhFy3XnIic"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lr = 0.001\n",
        "epochs = 10\n",
        "\n",
        "opt = Adam(lr=lr, decay=lr / (epochs * 0.5))\n",
        "model.compile(loss='categorical_crossentropy', optimizer=opt, metrics=['accuracy'])"
      ],
      "metadata": {
        "trusted": true,
        "id": "klGz99LUnIid"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# JY's code ; SMOTE for oversampling\n",
        "\n",
        "from imblearn.over_sampling import SMOTE\n",
        "\n",
        "data = X_train\n",
        "labels = y_train\n",
        "\n",
        "def smote(data, labels): \n",
        "  \n",
        "  X = data.reshape(len(data), -1)\n",
        "  y = labels\n",
        "  smt = SMOTE(sampling_strategy='not majority', k_neighbors=5, n_jobs=-1)\n",
        "  X_smote, y_smote = smt.fit_resample(X, y)\n",
        "  X_smote = X_smote.reshape((-1, )+ data.shape[1:]) \n",
        "\n",
        "  return  X_smote, y_smote\n",
        "\n",
        "data, labels = smote(data, labels)\n",
        "history = model.fit(data, labels, batch_size = 32, epochs = epochs, validation_data = (X_val, y_val))\n",
        "\n",
        "'''\n",
        "from keras import backend as K\n",
        "\n",
        "def recall_m(y_true, y_pred):\n",
        "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
        "    possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
        "    recall = true_positives / (possible_positives + K.epsilon())\n",
        "    return recall\n",
        "\n",
        "def precision_m(y_true, y_pred):\n",
        "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
        "    predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
        "    precision = true_positives / (predicted_positives + K.epsilon())\n",
        "    return precision\n",
        "\n",
        "def f1_m(y_true, y_pred):\n",
        "    precision = precision_m(y_true, y_pred)\n",
        "    recall = recall_m(y_true, y_pred)\n",
        "    return 2*((precision*recall)/(precision+recall+K.epsilon()))\n",
        "\n",
        "# compile the model\n",
        "model.compile(optimizer=opt, loss='categorical_crossentropy', metrics=['acc',f1_m,precision_m, recall_m])\n",
        "\n",
        "# fit the model\n",
        "history = model.fit(data, labels, validation_data = (X_val, y_val), epochs=1, verbose=0)\n",
        "\n",
        "# evaluate the model\n",
        "loss, accuracy, f1_score, precision, recall = model.evaluate(X_val, y_val, verbose=0)\n",
        "'''"
      ],
      "metadata": {
        "id": "UJRhWDIQAzb7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Augmenting the data and training the model"
      ],
      "metadata": {
        "id": "DG4XDXJknIid"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "aug = ImageDataGenerator(\n",
        "    rotation_range = 10,\n",
        "    zoom_range=0.15,\n",
        "    width_shift_range=0.1,\n",
        "    height_shift_range=0.1,\n",
        "    shear_range=0.15,\n",
        "    horizontal_flip=False,\n",
        "    vertical_flip=False,\n",
        "    fill_mode=\"nearest\")\n",
        "\n",
        "history = model.fit(aug.flow(X_train, y_train, batch_size = 32), epochs=epochs, validation_data=(X_val, y_val))"
      ],
      "metadata": {
        "trusted": true,
        "id": "fP56oQBZnIid"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Evaluating the model"
      ],
      "metadata": {
        "id": "a9wXYPlJnIid"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pd.DataFrame(history.history).plot(figsize=(8, 5))\n",
        "plt.grid(True)\n",
        "plt.gca().set_ylim(0, 1)\n",
        "plt.show()"
      ],
      "metadata": {
        "trusted": true,
        "id": "pMhkTVQwnIid"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluation HJ\n",
        "test = pd.read_csv(data_dir_test + '/Test.csv')\n",
        "imgs = test[\"Path\"].values\n",
        "data =[]\n",
        "\n",
        "for img in imgs:\n",
        "    try:\n",
        "        image = cv2.imread(data_dir_test + '/' +img)\n",
        "        image_fromarray = Image.fromarray(image, 'RGB')\n",
        "        resize_image = image_fromarray.resize((IMG_HEIGHT, IMG_WIDTH))\n",
        "        data.append(np.array(resize_image))\n",
        "    except:\n",
        "        print(\"Error in \" + img)\n",
        "\n",
        "X_test = np.array(data)\n",
        "X_test = X_test/255\n",
        "\n",
        "pred = model.predict(X_test)\n",
        "classes_x = np.argmax(pred,axis=1)"
      ],
      "metadata": {
        "id": "J9Jq0IhpvVM-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Loading the test data and running the predictions"
      ],
      "metadata": {
        "id": "20lC2-ZgnIie"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "test = pd.read_csv(data_dir_test + '/Test.csv')\n",
        "\n",
        "labels = test[\"ClassId\"].values\n",
        "imgs = test[\"Path\"].values\n",
        "\n",
        "data =[]\n",
        "\n",
        "for img in imgs:\n",
        "    try:\n",
        "        image = cv2.imread(data_dir_test + '/' +img)\n",
        "        image_fromarray = Image.fromarray(image, 'RGB')\n",
        "        resize_image = image_fromarray.resize((IMG_HEIGHT, IMG_WIDTH))\n",
        "        data.append(np.array(resize_image))\n",
        "    except:\n",
        "        print(\"Error in \" + img)\n",
        "X_test = np.array(data)\n",
        "X_test = X_test/255\n",
        "\n",
        "pred = model.predict(X_test)\n",
        "pred = np.argmax(pred, axis=1)\n",
        "\n",
        "#Accuracy with the test data\n",
        "print('Test Data accuracy: ',accuracy_score(labels, pred)*100)"
      ],
      "metadata": {
        "trusted": true,
        "id": "rmGgRuGXnIie"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Visualizing the confusion matrix"
      ],
      "metadata": {
        "id": "xUK_9n0xnIie"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "cf = confusion_matrix(labels, pred)"
      ],
      "metadata": {
        "trusted": true,
        "id": "WDQ0SP3BnIie"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import seaborn as sns\n",
        "df_cm = pd.DataFrame(cf, index = classes,  columns = classes)\n",
        "plt.figure(figsize = (20,20))\n",
        "sns.heatmap(df_cm, annot=True)"
      ],
      "metadata": {
        "trusted": true,
        "id": "lEWvM8_XnIie"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Classification report"
      ],
      "metadata": {
        "id": "_417pWJQnIie"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import classification_report\n",
        "\n",
        "print(classification_report(labels, pred))"
      ],
      "metadata": {
        "trusted": true,
        "id": "MDRXNw3CnIif"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Predictions on Test Data"
      ],
      "metadata": {
        "id": "aZuim_H9nIif"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize = (25, 25))\n",
        "\n",
        "start_index = 0\n",
        "for i in range(25):\n",
        "    plt.subplot(5, 5, i + 1)\n",
        "    plt.grid(False)\n",
        "    plt.xticks([])\n",
        "    plt.yticks([])\n",
        "    prediction = pred[start_index + i]\n",
        "    actual = labels[start_index + i]\n",
        "    col = 'g'\n",
        "    if prediction != actual:\n",
        "        col = 'r'\n",
        "    plt.xlabel('Actual={} || Pred={}'.format(actual, prediction), color = col)\n",
        "    plt.imshow(X_test[start_index + i])\n",
        "plt.show()"
      ],
      "metadata": {
        "trusted": true,
        "id": "gdTDvahnnIif"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# For Suggestion\n",
        "\n",
        "suggest_test = '/content/drive/MyDrive/Colab Notebooks/snu/project/data/data'\n",
        "\n",
        "# Resizing the images to 40x40x3\n",
        "IMG_HEIGHT = 40\n",
        "IMG_WIDTH = 40\n",
        "channels = 3\n",
        "\n",
        "image_data = []\n",
        "image_predict = []\n",
        "\n",
        "\n",
        "path = suggest_test + '/Test/'\n",
        "images = os.listdir(path)\n",
        "\n",
        "for img in images:\n",
        "    try:\n",
        "        image = cv2.imread(path + '/' + img)\n",
        "        image_fromarray = Image.fromarray(image, 'RGB')\n",
        "        resize_image = image_fromarray.resize((IMG_HEIGHT, IMG_WIDTH))\n",
        "        image_data.append(np.array(resize_image))\n",
        "        image_predict.append(img)\n",
        "    except:\n",
        "        print(i,\" iteration\",\" and Error in \" + img)\n",
        "\n",
        "X_test = np.array(image_data)\n",
        "X_test = X_test/255\n",
        "\n",
        "pred_suggest = model.predict(X_test)\n",
        "suggest = np.argmax(pred_suggest,axis=1)"
      ],
      "metadata": {
        "id": "wMVWQVXIHdST"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "image_predict = np.array(image_predict)\n",
        "\n",
        "print(image_predict.shape)\n",
        "print(suggest.shape)\n",
        "print(X_test.shape)"
      ],
      "metadata": {
        "id": "Y89fc2jRugyC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/drive/MyDrive/Colab Notebooks/snu/project/data/data"
      ],
      "metadata": {
        "id": "3Gl6fttXqm53"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Save data as csv\n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "data = suggest\n",
        "df = pd.DataFrame(data)\n",
        "df2 = pd.DataFrame(image_predict)\n",
        "df.to_csv('HD_proj_team1_1.csv', index = False)\n",
        "df2.to_csv('HD_proj_team1_1_image_name.csv', index = False)"
      ],
      "metadata": {
        "id": "M2lJuPtOp-3m"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}