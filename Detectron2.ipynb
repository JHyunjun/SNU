{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/JHyunjun/SNU/blob/main/Detectron2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QHnVupBBn9eR"
      },
      "source": [
        "# Detectron2 Tutorial: A Primer\n",
        "\n",
        "![det](https://dl.fbaipublicfiles.com/detectron2/Detectron2-Logo-Horz.png)\n",
        "\n",
        "This notebook will walk through [the Detectron2 tutorial from DLology](https://www.dlology.com/blog/how-to-train-detectron2-with-custom-coco-datasets/).\n",
        "\n",
        "We show how one can fine-tune a pretrained model on a subset of the COCO dataset with a few lines of codes."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vM54r6jlKTII"
      },
      "source": [
        "# Install detectron2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "9_FzH13EjseR",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "f6cb63ad-7b03-4e66-eaf3-f899334267e1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting git+https://github.com/facebookresearch/fvcore.git\n",
            "  Cloning https://github.com/facebookresearch/fvcore.git to /tmp/pip-req-build-9oxhw55k\n",
            "  Running command git clone -q https://github.com/facebookresearch/fvcore.git /tmp/pip-req-build-9oxhw55k\n",
            "Collecting numpy\n",
            "  Downloading numpy-1.21.6-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (15.7 MB)\n",
            "\u001b[K     |████████████████████████████████| 15.7 MB 5.1 MB/s \n",
            "\u001b[?25hCollecting yacs>=0.1.6\n",
            "  Downloading yacs-0.1.8-py3-none-any.whl (14 kB)\n",
            "Collecting pyyaml>=5.1\n",
            "  Downloading PyYAML-6.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (596 kB)\n",
            "\u001b[K     |████████████████████████████████| 596 kB 68.1 MB/s \n",
            "\u001b[?25hCollecting tqdm\n",
            "  Downloading tqdm-4.64.0-py2.py3-none-any.whl (78 kB)\n",
            "\u001b[K     |████████████████████████████████| 78 kB 8.1 MB/s \n",
            "\u001b[?25hCollecting termcolor>=1.1\n",
            "  Downloading termcolor-1.1.0.tar.gz (3.9 kB)\n",
            "Collecting Pillow\n",
            "  Downloading Pillow-9.2.0-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 3.1 MB 56.1 MB/s \n",
            "\u001b[?25hCollecting tabulate\n",
            "  Downloading tabulate-0.8.10-py3-none-any.whl (29 kB)\n",
            "Collecting iopath>=0.1.7\n",
            "  Downloading iopath-0.1.10.tar.gz (42 kB)\n",
            "\u001b[K     |████████████████████████████████| 42 kB 1.2 MB/s \n",
            "\u001b[?25hCollecting typing_extensions\n",
            "  Downloading typing_extensions-4.3.0-py3-none-any.whl (25 kB)\n",
            "Collecting portalocker\n",
            "  Downloading portalocker-2.5.1-py2.py3-none-any.whl (15 kB)\n",
            "Building wheels for collected packages: fvcore, iopath, termcolor\n",
            "  Building wheel for fvcore (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for fvcore: filename=fvcore-0.1.5-py3-none-any.whl size=65332 sha256=91bf80cafde693d7a0ea202bfb7c6c03b0826495ad2174286e0af2d0470f5342\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-ivv1m1hl/wheels/24/1d/09/8167de727fe5b74f832b6fcb5d9069d8f03ca29f337bfe484d\n",
            "  Building wheel for iopath (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for iopath: filename=iopath-0.1.10-py3-none-any.whl size=31549 sha256=5618adc05aaf640947d31e35c575844466986e02c71a4d56fd9671d138aac1bc\n",
            "  Stored in directory: /root/.cache/pip/wheels/aa/cc/ed/ca4e88beef656b01c84b9185196513ef2faf74a5a379b043a7\n",
            "  Building wheel for termcolor (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for termcolor: filename=termcolor-1.1.0-py3-none-any.whl size=4848 sha256=b9cfb542807519e2719274b3da5cc6fa41fed994e1b469dcd603befab7d632e2\n",
            "  Stored in directory: /root/.cache/pip/wheels/3f/e3/ec/8a8336ff196023622fbcb36de0c5a5c218cbb24111d1d4c7f2\n",
            "Successfully built fvcore iopath termcolor\n",
            "Installing collected packages: typing-extensions, tqdm, pyyaml, portalocker, yacs, termcolor, tabulate, Pillow, numpy, iopath, fvcore\n",
            "  Attempting uninstall: typing-extensions\n",
            "    Found existing installation: typing-extensions 4.1.1\n",
            "    Uninstalling typing-extensions-4.1.1:\n",
            "      Successfully uninstalled typing-extensions-4.1.1\n",
            "  Attempting uninstall: tqdm\n",
            "    Found existing installation: tqdm 4.64.0\n",
            "    Uninstalling tqdm-4.64.0:\n",
            "      Successfully uninstalled tqdm-4.64.0\n",
            "  Attempting uninstall: pyyaml\n",
            "    Found existing installation: PyYAML 3.13\n",
            "    Uninstalling PyYAML-3.13:\n",
            "      Successfully uninstalled PyYAML-3.13\n",
            "  Attempting uninstall: termcolor\n",
            "    Found existing installation: termcolor 1.1.0\n",
            "    Uninstalling termcolor-1.1.0:\n",
            "      Successfully uninstalled termcolor-1.1.0\n",
            "  Attempting uninstall: tabulate\n",
            "    Found existing installation: tabulate 0.8.10\n",
            "    Uninstalling tabulate-0.8.10:\n",
            "      Successfully uninstalled tabulate-0.8.10\n",
            "  Attempting uninstall: Pillow\n",
            "    Found existing installation: Pillow 7.1.2\n",
            "    Uninstalling Pillow-7.1.2:\n",
            "      Successfully uninstalled Pillow-7.1.2\n",
            "  Attempting uninstall: numpy\n",
            "    Found existing installation: numpy 1.21.6\n",
            "    Uninstalling numpy-1.21.6:\n",
            "      Successfully uninstalled numpy-1.21.6\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "thinc 8.1.0 requires typing-extensions<4.2.0,>=3.7.4.1; python_version < \"3.8\", but you have typing-extensions 4.3.0 which is incompatible.\n",
            "spacy 3.4.1 requires typing-extensions<4.2.0,>=3.7.4; python_version < \"3.8\", but you have typing-extensions 4.3.0 which is incompatible.\u001b[0m\n",
            "Successfully installed Pillow-9.2.0 fvcore-0.1.5 iopath-0.1.10 numpy-1.21.6 portalocker-2.5.1 pyyaml-6.0 tabulate-0.8.10 termcolor-1.1.0 tqdm-4.64.0 typing-extensions-4.3.0 yacs-0.1.8\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "PIL",
                  "numpy"
                ]
              }
            }
          },
          "metadata": {}
        },
        {
          "output_type": "error",
          "ename": "ImportError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-c302cd46ca97>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#!pip install -U torch torchvision\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msystem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'pip install git+https://github.com/facebookresearch/fvcore.git --force-reinstall'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorchvision\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__version__\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torchvision/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtorchvision\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdatasets\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtorchvision\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mio\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtorchvision\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmodels\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torchvision/datasets/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0m_optical_flow\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mKittiFlow\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mSintel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mFlyingChairs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mFlyingThings3D\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mHD1K\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mcaltech\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mCaltech101\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mCaltech256\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mceleba\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mCelebA\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mcifar\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mCIFAR10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mCIFAR100\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mcityscapes\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mCityscapes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torchvision/datasets/_optical_flow.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mPIL\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mImage\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimage\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0m_read_png_16\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mverify_str_arg\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mvision\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mVisionDataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torchvision/io/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0m_log_api_usage_once\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torchvision/utils.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mPIL\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mImage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mImageColor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mImageDraw\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mImageFont\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m __all__ = [\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/PIL/ImageFont.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mImage\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0m_deprecate\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdeprecate\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 37\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0m_util\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mis_directory\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mis_path\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     38\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mImportError\u001b[0m: cannot import name 'is_directory' from 'PIL._util' (/usr/local/lib/python3.7/dist-packages/PIL/_util.py)",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ],
          "errorDetails": {
            "actions": [
              {
                "action": "open_url",
                "actionText": "Open Examples",
                "url": "/notebooks/snippets/importing_libraries.ipynb"
              }
            ]
          }
        }
      ],
      "source": [
        "#!pip install -U torch torchvision\n",
        "!pip install git+https://github.com/facebookresearch/fvcore.git --force-reinstall\n",
        "import torch, torchvision\n",
        "torch.__version__"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B1Id2foQR8h2"
      },
      "source": [
        "```\n",
        "!pip install git+https://github.com/facebookresearch/fvcore.git --force-reinstall\n",
        "# restart runtime\n",
        "!git clone https://github.com/facebookresearch/detectron2 detectron2_repo\n",
        "!pip install -e detectron2_repo\n",
        "# restart runtime again\n",
        "```\n",
        "```\n",
        "!pip uninstall torch -y\n",
        "!pip uninstall torchvision -y\n",
        "!pip install torch==1.10.1+cu111 torchvision=0.11.2+cu111 -f https://download.pytorch.org/whl/torch_stable.html\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "b-i4hmGYk1dL",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "99cbc841-b6f8-41c8-9419-b5163df862cd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'detectron2_repo'...\n",
            "remote: Enumerating objects: 14489, done.\u001b[K\n",
            "remote: Counting objects:   1% (1/64)\u001b[K\rremote: Counting objects:   3% (2/64)\u001b[K\rremote: Counting objects:   4% (3/64)\u001b[K\rremote: Counting objects:   6% (4/64)\u001b[K\rremote: Counting objects:   7% (5/64)\u001b[K\rremote: Counting objects:   9% (6/64)\u001b[K\rremote: Counting objects:  10% (7/64)\u001b[K\rremote: Counting objects:  12% (8/64)\u001b[K\rremote: Counting objects:  14% (9/64)\u001b[K\rremote: Counting objects:  15% (10/64)\u001b[K\rremote: Counting objects:  17% (11/64)\u001b[K\rremote: Counting objects:  18% (12/64)\u001b[K\rremote: Counting objects:  20% (13/64)\u001b[K\rremote: Counting objects:  21% (14/64)\u001b[K\rremote: Counting objects:  23% (15/64)\u001b[K\rremote: Counting objects:  25% (16/64)\u001b[K\rremote: Counting objects:  26% (17/64)\u001b[K\rremote: Counting objects:  28% (18/64)\u001b[K\rremote: Counting objects:  29% (19/64)\u001b[K\rremote: Counting objects:  31% (20/64)\u001b[K\rremote: Counting objects:  32% (21/64)\u001b[K\rremote: Counting objects:  34% (22/64)\u001b[K\rremote: Counting objects:  35% (23/64)\u001b[K\rremote: Counting objects:  37% (24/64)\u001b[K\rremote: Counting objects:  39% (25/64)\u001b[K\rremote: Counting objects:  40% (26/64)\u001b[K\rremote: Counting objects:  42% (27/64)\u001b[K\rremote: Counting objects:  43% (28/64)\u001b[K\rremote: Counting objects:  45% (29/64)\u001b[K\rremote: Counting objects:  46% (30/64)\u001b[K\rremote: Counting objects:  48% (31/64)\u001b[K\rremote: Counting objects:  50% (32/64)\u001b[K\rremote: Counting objects:  51% (33/64)\u001b[K\rremote: Counting objects:  53% (34/64)\u001b[K\rremote: Counting objects:  54% (35/64)\u001b[K\rremote: Counting objects:  56% (36/64)\u001b[K\rremote: Counting objects:  57% (37/64)\u001b[K\rremote: Counting objects:  59% (38/64)\u001b[K\rremote: Counting objects:  60% (39/64)\u001b[K\rremote: Counting objects:  62% (40/64)\u001b[K\rremote: Counting objects:  64% (41/64)\u001b[K\rremote: Counting objects:  65% (42/64)\u001b[K\rremote: Counting objects:  67% (43/64)\u001b[K\rremote: Counting objects:  68% (44/64)\u001b[K\rremote: Counting objects:  70% (45/64)\u001b[K\rremote: Counting objects:  71% (46/64)\u001b[K\rremote: Counting objects:  73% (47/64)\u001b[K\rremote: Counting objects:  75% (48/64)\u001b[K\rremote: Counting objects:  76% (49/64)\u001b[K\rremote: Counting objects:  78% (50/64)\u001b[K\rremote: Counting objects:  79% (51/64)\u001b[K\rremote: Counting objects:  81% (52/64)\u001b[K\rremote: Counting objects:  82% (53/64)\u001b[K\rremote: Counting objects:  84% (54/64)\u001b[K\rremote: Counting objects:  85% (55/64)\u001b[K\rremote: Counting objects:  87% (56/64)\u001b[K\rremote: Counting objects:  89% (57/64)\u001b[K\rremote: Counting objects:  90% (58/64)\u001b[K\rremote: Counting objects:  92% (59/64)\u001b[K\rremote: Counting objects:  93% (60/64)\u001b[K\rremote: Counting objects:  95% (61/64)\u001b[K\rremote: Counting objects:  96% (62/64)\u001b[K\rremote: Counting objects:  98% (63/64)\u001b[K\rremote: Counting objects: 100% (64/64)\u001b[K\rremote: Counting objects: 100% (64/64), done.\u001b[K\n",
            "remote: Compressing objects: 100% (50/50), done.\u001b[K\n",
            "remote: Total 14489 (delta 24), reused 42 (delta 13), pack-reused 14425\u001b[K\n",
            "Receiving objects: 100% (14489/14489), 5.95 MiB | 23.52 MiB/s, done.\n",
            "Resolving deltas: 100% (10470/10470), done.\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Obtaining file:///content/detectron2_repo\n",
            "Requirement already satisfied: Pillow>=7.1 in /usr/local/lib/python3.7/dist-packages (from detectron2==0.6) (9.2.0)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (from detectron2==0.6) (3.2.2)\n",
            "Requirement already satisfied: pycocotools>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from detectron2==0.6) (2.0.4)\n",
            "Requirement already satisfied: termcolor>=1.1 in /usr/local/lib/python3.7/dist-packages (from detectron2==0.6) (1.1.0)\n",
            "Requirement already satisfied: yacs>=0.1.8 in /usr/local/lib/python3.7/dist-packages (from detectron2==0.6) (0.1.8)\n",
            "Requirement already satisfied: tabulate in /usr/local/lib/python3.7/dist-packages (from detectron2==0.6) (0.8.10)\n",
            "Requirement already satisfied: cloudpickle in /usr/local/lib/python3.7/dist-packages (from detectron2==0.6) (1.3.0)\n",
            "Requirement already satisfied: tqdm>4.29.0 in /usr/local/lib/python3.7/dist-packages (from detectron2==0.6) (4.64.0)\n",
            "Requirement already satisfied: tensorboard in /usr/local/lib/python3.7/dist-packages (from detectron2==0.6) (2.8.0)\n",
            "Requirement already satisfied: fvcore<0.1.6,>=0.1.5 in /usr/local/lib/python3.7/dist-packages (from detectron2==0.6) (0.1.5)\n",
            "Collecting iopath<0.1.10,>=0.1.7\n",
            "  Downloading iopath-0.1.9-py3-none-any.whl (27 kB)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.7/dist-packages (from detectron2==0.6) (0.16.0)\n",
            "Requirement already satisfied: pydot in /usr/local/lib/python3.7/dist-packages (from detectron2==0.6) (1.3.0)\n",
            "Collecting omegaconf>=2.1\n",
            "  Downloading omegaconf-2.2.2-py3-none-any.whl (79 kB)\n",
            "\u001b[K     |████████████████████████████████| 79 kB 4.0 MB/s \n",
            "\u001b[?25hCollecting hydra-core>=1.1\n",
            "  Downloading hydra_core-1.2.0-py3-none-any.whl (151 kB)\n",
            "\u001b[K     |████████████████████████████████| 151 kB 29.6 MB/s \n",
            "\u001b[?25hCollecting black==22.3.0\n",
            "  Downloading black-22.3.0-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.4 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.4 MB 67.1 MB/s \n",
            "\u001b[?25hCollecting timm\n",
            "  Downloading timm-0.6.7-py3-none-any.whl (509 kB)\n",
            "\u001b[K     |████████████████████████████████| 509 kB 65.6 MB/s \n",
            "\u001b[?25hCollecting fairscale\n",
            "  Downloading fairscale-0.4.6.tar.gz (248 kB)\n",
            "\u001b[K     |████████████████████████████████| 248 kB 75.5 MB/s \n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Installing backend dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "    Preparing wheel metadata ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from detectron2==0.6) (21.3)\n",
            "Collecting click>=8.0.0\n",
            "  Downloading click-8.1.3-py3-none-any.whl (96 kB)\n",
            "\u001b[K     |████████████████████████████████| 96 kB 6.7 MB/s \n",
            "\u001b[?25hRequirement already satisfied: typing-extensions>=3.10.0.0 in /usr/local/lib/python3.7/dist-packages (from black==22.3.0->detectron2==0.6) (4.3.0)\n",
            "Collecting platformdirs>=2\n",
            "  Downloading platformdirs-2.5.2-py3-none-any.whl (14 kB)\n",
            "Requirement already satisfied: tomli>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from black==22.3.0->detectron2==0.6) (2.0.1)\n",
            "Collecting mypy-extensions>=0.4.3\n",
            "  Downloading mypy_extensions-0.4.3-py2.py3-none-any.whl (4.5 kB)\n",
            "Collecting typed-ast>=1.4.2\n",
            "  Downloading typed_ast-1.5.4-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (843 kB)\n",
            "\u001b[K     |████████████████████████████████| 843 kB 55.6 MB/s \n",
            "\u001b[?25hCollecting pathspec>=0.9.0\n",
            "  Downloading pathspec-0.9.0-py2.py3-none-any.whl (31 kB)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from click>=8.0.0->black==22.3.0->detectron2==0.6) (4.12.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from fvcore<0.1.6,>=0.1.5->detectron2==0.6) (1.21.6)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.7/dist-packages (from fvcore<0.1.6,>=0.1.5->detectron2==0.6) (6.0)\n",
            "Collecting antlr4-python3-runtime==4.9.*\n",
            "  Downloading antlr4-python3-runtime-4.9.3.tar.gz (117 kB)\n",
            "\u001b[K     |████████████████████████████████| 117 kB 73.6 MB/s \n",
            "\u001b[?25hRequirement already satisfied: importlib-resources in /usr/local/lib/python3.7/dist-packages (from hydra-core>=1.1->detectron2==0.6) (5.9.0)\n",
            "Requirement already satisfied: portalocker in /usr/local/lib/python3.7/dist-packages (from iopath<0.1.10,>=0.1.7->detectron2==0.6) (2.5.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib->detectron2==0.6) (0.11.0)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->detectron2==0.6) (3.0.9)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->detectron2==0.6) (2.8.2)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->detectron2==0.6) (1.4.4)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.1->matplotlib->detectron2==0.6) (1.15.0)\n",
            "Requirement already satisfied: torch>=1.8.0 in /usr/local/lib/python3.7/dist-packages (from fairscale->detectron2==0.6) (1.12.0+cu113)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->click>=8.0.0->black==22.3.0->detectron2==0.6) (3.8.1)\n",
            "Requirement already satisfied: grpcio>=1.24.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard->detectron2==0.6) (1.47.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard->detectron2==0.6) (0.6.1)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard->detectron2==0.6) (1.0.1)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.7/dist-packages (from tensorboard->detectron2==0.6) (0.37.1)\n",
            "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.7/dist-packages (from tensorboard->detectron2==0.6) (1.2.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard->detectron2==0.6) (3.4.1)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard->detectron2==0.6) (0.4.6)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard->detectron2==0.6) (57.4.0)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard->detectron2==0.6) (1.35.0)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard->detectron2==0.6) (2.23.0)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard->detectron2==0.6) (1.8.1)\n",
            "Requirement already satisfied: protobuf>=3.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard->detectron2==0.6) (3.17.3)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard->detectron2==0.6) (0.2.8)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard->detectron2==0.6) (4.2.4)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard->detectron2==0.6) (4.9)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard->detectron2==0.6) (1.3.1)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard->detectron2==0.6) (0.4.8)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard->detectron2==0.6) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard->detectron2==0.6) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard->detectron2==0.6) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard->detectron2==0.6) (2022.6.15)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard->detectron2==0.6) (3.2.0)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.7/dist-packages (from timm->detectron2==0.6) (0.13.0+cu113)\n",
            "Building wheels for collected packages: antlr4-python3-runtime, fairscale\n",
            "  Building wheel for antlr4-python3-runtime (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for antlr4-python3-runtime: filename=antlr4_python3_runtime-4.9.3-py3-none-any.whl size=144575 sha256=fb79a8bd02fcc9f4e048ce5820668cf565d0fa0b7314410b7e0eff6d7122ee83\n",
            "  Stored in directory: /root/.cache/pip/wheels/8b/8d/53/2af8772d9aec614e3fc65e53d4a993ad73c61daa8bbd85a873\n",
            "  Building wheel for fairscale (PEP 517) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for fairscale: filename=fairscale-0.4.6-py3-none-any.whl size=307252 sha256=b26887980fb4fef7597db6c2178f1ea30a12f26ef9f042f6d4dbdbe9f798c7bd\n",
            "  Stored in directory: /root/.cache/pip/wheels/4e/4f/0b/94c29ea06dfad93260cb0377855f87b7b863312317a7f69fe7\n",
            "Successfully built antlr4-python3-runtime fairscale\n",
            "Installing collected packages: antlr4-python3-runtime, typed-ast, platformdirs, pathspec, omegaconf, mypy-extensions, iopath, click, timm, hydra-core, fairscale, black, detectron2\n",
            "  Attempting uninstall: iopath\n",
            "    Found existing installation: iopath 0.1.10\n",
            "    Uninstalling iopath-0.1.10:\n",
            "      Successfully uninstalled iopath-0.1.10\n",
            "  Attempting uninstall: click\n",
            "    Found existing installation: click 7.1.2\n",
            "    Uninstalling click-7.1.2:\n",
            "      Successfully uninstalled click-7.1.2\n",
            "  Running setup.py develop for detectron2\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "spacy 3.4.1 requires typing-extensions<4.2.0,>=3.7.4; python_version < \"3.8\", but you have typing-extensions 4.3.0 which is incompatible.\n",
            "flask 1.1.4 requires click<8.0,>=5.1, but you have click 8.1.3 which is incompatible.\u001b[0m\n",
            "Successfully installed antlr4-python3-runtime-4.9.3 black-22.3.0 click-8.1.3 detectron2-0.6 fairscale-0.4.6 hydra-core-1.2.0 iopath-0.1.9 mypy-extensions-0.4.3 omegaconf-2.2.2 pathspec-0.9.0 platformdirs-2.5.2 timm-0.6.7 typed-ast-1.5.4\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "pydevd_plugins"
                ]
              }
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "!git clone https://github.com/facebookresearch/detectron2 detectron2_repo\n",
        "!pip install -e detectron2_repo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZyAvNCJMmvFF"
      },
      "outputs": [],
      "source": [
        "# You may need to restart your runtime prior to this, to let your installation take effect\n",
        "# Some basic setup\n",
        "# Setup detectron2 logger\n",
        "import detectron2\n",
        "from detectron2.utils.logger import setup_logger\n",
        "setup_logger()\n",
        "\n",
        "# import some common libraries\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import cv2\n",
        "from google.colab.patches import cv2_imshow\n",
        "\n",
        "# import some common detectron2 utilities\n",
        "from detectron2 import model_zoo\n",
        "from detectron2.engine import DefaultPredictor\n",
        "from detectron2.config import get_cfg\n",
        "from detectron2.utils.visualizer import Visualizer\n",
        "from detectron2.data import MetadataCatalog, DatasetCatalog"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vk4gID50K03a"
      },
      "source": [
        "# Run a pre-trained detectron2 model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "axSfx7jzbpF3"
      },
      "source": [
        "### Why running a pre-trained model?\n",
        "\n",
        "![](https://baekyeongmin.github.io/images/lxmert/architecture.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JgKyUL4pngvE"
      },
      "source": [
        "We first download an image from the COCO dataset:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dq9GY37ml1kr"
      },
      "outputs": [],
      "source": [
        "!wget http://images.cocodataset.org/val2017/000000439715.jpg -q -O input.jpg\n",
        "im = cv2.imread(\"./input.jpg\")\n",
        "cv2_imshow(im)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uM1thbN-ntjI"
      },
      "source": [
        "Then, we create a detectron2 config and a detectron2 `DefaultPredictor` to run inference on this image."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xi9-YchoFFQ4"
      },
      "source": [
        "* Feature Pyramid Networks (FPN)\n",
        "\n",
        "![](https://blog.kakaocdn.net/dn/16xz2/btqubeXA8WS/mQUOaaqCKPwUL5cVYDMl8k/img.png)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HUjkwRsOn1O0"
      },
      "outputs": [],
      "source": [
        "cfg = get_cfg()\n",
        "# add project-specific config (e.g., TensorMask) here if you're not running a model in detectron2's core library\n",
        "cfg.merge_from_file(model_zoo.get_config_file(\"COCO-Detection/faster_rcnn_R_50_FPN_3x.yaml\"))\n",
        "cfg.MODEL.ROI_HEADS.SCORE_THRESH_TEST = 0.5  # set threshold for this model\n",
        "# Find a model from detectron2's model zoo. You can use the https://dl.fbaipublicfiles... url as well\n",
        "cfg.MODEL.WEIGHTS = model_zoo.get_checkpoint_url(\"COCO-Detection/faster_rcnn_R_50_FPN_3x.yaml\")\n",
        "predictor = DefaultPredictor(cfg)\n",
        "outputs = predictor(im)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7d3KxiHO_0gb"
      },
      "outputs": [],
      "source": [
        "# look at the outputs. See https://detectron2.readthedocs.io/tutorials/models.html#model-output-format for specification\n",
        "print((outputs.keys()))\n",
        "print(outputs[\"instances\"].pred_classes)\n",
        "print(outputs[\"instances\"].pred_boxes)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8IRGo8d0qkgR"
      },
      "outputs": [],
      "source": [
        "# We can use `Visualizer` to draw the predictions on the image.\n",
        "v = Visualizer(im[:, :, ::-1], MetadataCatalog.get(cfg.DATASETS.TRAIN[0]), scale=1.2)\n",
        "out = v.draw_instance_predictions(outputs[\"instances\"].to(\"cpu\"))\n",
        "cv2_imshow(out.get_image()[:, :, ::-1])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b2bjrfb2LDeo"
      },
      "source": [
        "# Train on a custom COCO dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tjbUIhSxUdm_"
      },
      "source": [
        "In this section, we show how to train an existing detectron2 model on a custom dataset in a new format.\n",
        "\n",
        "We use [the fruits nuts segmentation dataset](https://github.com/Tony607/mmdetection_instance_segmentation_demo)\n",
        "which only has 3 classes: data, fig, and hazelnut.\n",
        "We'll train a segmentation model from an existing model pre-trained on the COCO dataset, available in detectron2's model zoo.\n",
        "\n",
        "Note that the COCO dataset does not have the \"data\", \"fig\" and \"hazelnut\" categories."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4Qg7zSVOulkb"
      },
      "outputs": [],
      "source": [
        "# download, decompress the data\n",
        "!wget https://github.com/Tony607/detectron2_instance_segmentation_demo/releases/download/V0.1/data.zip\n",
        "!unzip data.zip > /dev/null"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tVJoOm6LVJwW"
      },
      "source": [
        "Register the fruits_nuts dataset to detectron2, following the [detectron2 custom dataset tutorial](https://detectron2.readthedocs.io/tutorials/datasets.html).\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Lnkg1PByUjGQ"
      },
      "outputs": [],
      "source": [
        "from detectron2.data.datasets import register_coco_instances\n",
        "register_coco_instances(\"fruits_nuts\", {}, \"./data/trainval.json\", \"./data/images\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MWknKqWTWIw9"
      },
      "outputs": [],
      "source": [
        "fruits_nuts_metadata = MetadataCatalog.get(\"fruits_nuts\")\n",
        "dataset_dicts = DatasetCatalog.get(\"fruits_nuts\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6ljbWTX0Wi8E"
      },
      "source": [
        "To verify the data loading is correct, let's visualize the annotations of randomly selected samples in the training set:\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UkNbUzUOLYf0"
      },
      "outputs": [],
      "source": [
        "import random\n",
        "\n",
        "for d in random.sample(dataset_dicts, 3):\n",
        "    img = cv2.imread(d[\"file_name\"])\n",
        "    visualizer = Visualizer(img[:, :, ::-1], metadata=fruits_nuts_metadata, scale=0.5)\n",
        "    vis = visualizer.draw_dataset_dict(d)\n",
        "    cv2_imshow(vis.get_image()[:, :, ::-1])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wlqXIXXhW8dA"
      },
      "source": [
        "Now, let's fine-tune a coco-pretrained R50-FPN Mask R-CNN model on the fruits_nuts dataset. It takes ~6 minutes to train 300 iterations on Colab's K80 GPU.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7unkuuiqLdqd"
      },
      "outputs": [],
      "source": [
        "from detectron2.engine import DefaultTrainer\n",
        "from detectron2.config import get_cfg\n",
        "import os\n",
        "\n",
        "cfg = get_cfg()\n",
        "cfg.merge_from_file(\"./detectron2_repo/configs/COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_3x.yaml\")\n",
        "cfg.DATASETS.TRAIN = (\"fruits_nuts\",)\n",
        "cfg.DATASETS.TEST = ()   # no metrics implemented for this dataset\n",
        "cfg.DATALOADER.NUM_WORKERS = 2\n",
        "cfg.MODEL.WEIGHTS = \"detectron2://COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_3x/137849600/model_final_f10217.pkl\"  # initialize from model zoo\n",
        "cfg.SOLVER.IMS_PER_BATCH = 2\n",
        "cfg.SOLVER.BASE_LR = 0.02\n",
        "cfg.SOLVER.MAX_ITER = 100    # 300 iterations seems good enough, but you can certainly train longer\n",
        "cfg.MODEL.ROI_HEADS.BATCH_SIZE_PER_IMAGE = 128   # faster, and good enough for this toy dataset\n",
        "cfg.MODEL.ROI_HEADS.NUM_CLASSES = 3  # 3 classes (data, fig, hazelnut)\n",
        "\n",
        "os.makedirs(cfg.OUTPUT_DIR, exist_ok=True)\n",
        "trainer = DefaultTrainer(cfg)\n",
        "trainer.resume_or_load(resume=False)\n",
        "trainer.train()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0e4vdDIOXyxF"
      },
      "source": [
        "Now, we perform inference with the trained model on the fruits_nuts dataset. First, let's create a predictor using the model we just trained:\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ya5nEuMELeq8"
      },
      "outputs": [],
      "source": [
        "cfg.MODEL.WEIGHTS = os.path.join(cfg.OUTPUT_DIR, \"model_final.pth\")\n",
        "cfg.MODEL.ROI_HEADS.SCORE_THRESH_TEST = 0.5   # set the testing threshold for this model\n",
        "cfg.DATASETS.TEST = (\"fruits_nuts\", )\n",
        "predictor = DefaultPredictor(cfg)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qWq1XHfDWiXO"
      },
      "source": [
        "Then, we randomly select several samples to visualize the prediction results."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "U5LhISJqWXgM"
      },
      "outputs": [],
      "source": [
        "from detectron2.utils.visualizer import ColorMode\n",
        "\n",
        "for d in random.sample(dataset_dicts, 3):    \n",
        "    im = cv2.imread(d[\"file_name\"])\n",
        "    outputs = predictor(im)\n",
        "    v = Visualizer(im[:, :, ::-1],\n",
        "                   metadata=fruits_nuts_metadata, \n",
        "                   scale=0.8, \n",
        "                   instance_mode=ColorMode.IMAGE_BW   # remove the colors of unsegmented pixels\n",
        "    )\n",
        "    v = v.draw_instance_predictions(outputs[\"instances\"].to(\"cpu\"))\n",
        "    cv2_imshow(v.get_image()[:, :, ::-1])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "t_bo0cypwllj"
      },
      "outputs": [],
      "source": [
        "fruits_nuts_metadata"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wZ6lYrCqLLLW"
      },
      "source": [
        "## Benchmark inference speed"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PxRHYcAC_Z0f"
      },
      "outputs": [],
      "source": [
        "import time\n",
        "times = []\n",
        "for i in range(20):\n",
        "    start_time = time.time()\n",
        "    outputs = predictor(im)\n",
        "    delta = time.time() - start_time\n",
        "    times.append(delta)\n",
        "mean_delta = np.array(times).mean()\n",
        "fps = 1 / mean_delta\n",
        "print(\"Average(sec):{:.2f},fps:{:.2f}\".format(mean_delta, fps))"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "[Day 6-1] Detectron2 Introduction.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}